{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST 手寫數字辨識 (MNIST_CNN_TF)\n",
    "\n",
    "2017/07/16  \n",
    "Jay Hsu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips:\n",
    "- 記得要download data set: \n",
    "[Mnist](https://github.com/Backlu/tf-keras-tutorial/blob/master/basic/mnist.pkl.xz)\n",
    "- 在command前面加** ! **可以執行console command\n",
    "- 在command前面加** ? **可以查詢Help\n",
    "- 什麼是one-hot representation:\n",
    "[one-hot](https://www.quora.com/What-is-one-hot-encoding-and-when-is-it-used-in-data-science)  \n",
    "- 好用的markdown語法\n",
    "[markdown](https://www.zybuluo.com/codeep/note/163962#1如何输入一个方程式序列)  \n",
    "<br>\n",
    "- import PIL error : pip install Pillow\n",
    "- import pandas error: pip install pandas\n",
    "- import lzma error: 請用python 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "-  [Import Package & Functions](#import) \n",
    "-  [1. Import MNIST Data](#Import Data) \n",
    "-  [2. 開始Deep Learning - CNN](#開始Deep Learning)  \n",
    "-  [3. 補充資料](#補充資料)\n",
    "-  [4. Homework](#Homework)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='import'></a>\n",
    "## Import Package & Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import lzma\n",
    "import pickle\n",
    "from IPython.display import display\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def showX(X):\n",
    "    int_X = (X*255).clip(0,255).astype('uint8')\n",
    "    # N*784 -> N*28*28 -> 28*N*28 -> 28 * 28N\n",
    "    int_X_reshape = int_X.reshape(-1,28,28).swapaxes(0,1).reshape(28,-1)\n",
    "    display(Image.fromarray(int_X_reshape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updateProgress(msg):\n",
    "    sys.stdout.write('\\r')\n",
    "    sys.stdout.write(msg)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var, name):  \n",
    "    with tf.name_scope('summaries_'+str(name)):  \n",
    "        mean = tf.reduce_mean(var)  \n",
    "        tf.summary.scalar('mean', mean)  \n",
    "        stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))  \n",
    "        tf.summary.scalar('stddev', stddev)  \n",
    "        tf.summary.scalar('max', tf.reduce_max(var))  \n",
    "        tf.summary.scalar('min', tf.reduce_min(var))  \n",
    "        tf.summary.histogram('histogram', var)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Import MNIST Data'></a>\n",
    "## 1. Import MNIST Data\n",
    "#### 先把MNIST資料讀進來\n",
    "- Training Data: 訓練Model\n",
    "- Validataion Data: 訓練Model的時候, 同步監控目前模型的好壞\n",
    "- Testing Data: 訓練結束後, 評估模型的好壞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list裡的前面是picture X [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "後面是label Y [5 0 4 ..., 8 4 8]\n"
     ]
    }
   ],
   "source": [
    "with lzma.open(\"mnist.pkl.xz\", 'rb') as f:\n",
    "    train_set, validation_set, test_set = pickle.load(f, encoding='latin1')\n",
    "    \n",
    "print('list裡的前面是picture X',train_set[0])\n",
    "print('後面是label Y',train_set[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size: 50000\n",
      "validataion data size: 10000\n",
      "testing data size: 10000\n",
      "picture shape: (784,)\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y = train_set\n",
    "validation_X, validation_y = validation_set\n",
    "test_X, test_y = test_set\n",
    "print('training data size:',len(train_X))\n",
    "print('validataion data size:',len(validation_X))\n",
    "print('testing data size:',len(test_X))\n",
    "print('picture shape:',train_X[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 把Y label變成one-hot representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_Y = np.eye(10)[train_y]\n",
    "test_Y = np.eye(10)[test_y]\n",
    "validation_Y = np.eye(10)[validation_y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='開始Deep Learning'></a>\n",
    "## 2. 開始Deep Learning - CNN\n",
    "- CNN Motivation: 用來做影像辨識  \n",
    "<br>  \n",
    "- 影像辨識的3個重要的性質(Property) \n",
    "  - Property 1: 重要的Pattern通常出現在圖片的一小部分, 而不是整張圖片\n",
    "  - Property 2: 同樣的Pattern會出現在圖片的不同區域\n",
    "  - Property 3: 對圖片做subsampling而不會影響圖片的辨識結果  \n",
    "<br>  \n",
    "- CNN的三個重要功能/操作 \n",
    "  - Convolution \n",
    "    - Filter: 用來detect圖像上的小區域pattern, 當detect到pattern時output的值就會特別大, 一張圖片上可能有很多個區域都有pattern \n",
    "    - Stride: Filter一次在圖像上移動幾個pixel\n",
    "    - padding: 為了維持Filter後的圖片大小, 可以在圖片周圍補0\n",
    "    - CNN其實是Fully Connect的簡化版, 使用了較少的parameter\n",
    "  - Max pooling\n",
    "    - group matrix裡的element\n",
    "    - 每一個group選一個最大的\n",
    "    - 不一定要max, 也可以average\n",
    "  - Flatten\n",
    "    - 把image形狀拉成直的\n",
    "    - 目的是為了做最後的分類  \n",
    "<br>   \n",
    "- Overview\n",
    "  - matrix calculation process\n",
    "  - parameter qty in each layer  \n",
    "<br>  \n",
    "- some tips: \n",
    "  - 靠近input的layer偵測比較單純的pattern, 所以channel設定較小\n",
    "  - 靠近output的layer偵測比較抽象的pattern, 所以channel設定較大  \n",
    "<br>\n",
    "- 參考圖片：\n",
    "![](img/cnn_1.gif)\n",
    "![](img/cnn_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Deep Learning 3 Steps \n",
    "    - Define Function Set\n",
    "        -  [A. 定義參數](#定義參數) \n",
    "        -  [B. 設計一個Model從X預測Y](#設計一個) \n",
    "    - Evaluate goodness of functions\n",
    "        -  [C. 選一個loss function,](#選一個loss) \n",
    "        -  [D. 選一個optimizer](#選一個o) \n",
    "    - Choose the best function\n",
    "        -  [E. 開始執行訓練](#開始執行) \n",
    "        -  [F. 算一下正確率](#算一下正)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='定義參數'></a>\n",
    "### A. 定義參數(Placeholder, Variable, Constant)\n",
    "tips: 把要餵進Model的資料X,Y定義成placeholder, 把要讓電腦幫忙找的權重W,B定義成Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, shape=[None, 784], name='X')\n",
    "Y_ = tf.placeholder(tf.float32, shape=[None, 10], name='Y_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 設定 weight 和 bais\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape=shape, stddev=0.1)\n",
    "    W = tf.Variable(initial)\n",
    "    variable_summaries(W,'Weight')\n",
    "    return W\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(value=0.1, shape=shape)\n",
    "    B = tf.Variable(initial)\n",
    "    variable_summaries(B,'Bias')\n",
    "    return B\n",
    "# 設定 cnn 的 layers\n",
    "def conv2d(X, W):\n",
    "    return tf.nn.conv2d(X, W, strides=[1,1,1,1], padding='SAME',use_cudnn_on_gpu=True)\n",
    "    #stride:每次移動步伐, padding:在圖片的四周補0, SAME就是補到conv後要和原圖一樣大張\n",
    "def max_pool_2x2(X):\n",
    "    return tf.nn.max_pool(X, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    #ksize:框框大小, stride:每次移動步伐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='設計一個'></a>\n",
    "###  B. 設計一個Model從X & X history預測Y  \n",
    "Input Layer: X  \n",
    "Hidden Layer 1: $H_1=pooling(f(W_1(X)+B_1)$  \n",
    "Hidden Layer 2: $H_2=pooling(f_2(W_2H_1+B_2))$  \n",
    "Output Layer : $Y=pooling(f_3(W_3H_2+B_3))$  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1. Input Layer 輸入層\n",
    "- do nothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2. Hidden Layer 隱藏層 x 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**  Fisrt Convolution + Max Pooling layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('conv1'):\n",
    "    ## variables\n",
    "    W_conv1 = weight_variable([3,3,1,32]) # filter_height, filter_width, in_channels, out_channels\n",
    "    b_conv1 = bias_variable([32])\n",
    "    ## build the layer\n",
    "    X_image = tf.reshape(X, [-1, 28, 28,1]) # batch, in_height, in_width, in_channels\n",
    "    h_conv1 = tf.nn.relu(conv2d(X_image, W_conv1) + b_conv1)\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Second Convolution + Max Pooling layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('conv2'):\n",
    "    ## variables\n",
    "    W_conv2 = weight_variable([3,3,32,64])\n",
    "    b_conv2 = bias_variable([64])\n",
    "    ## build the layer\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "    h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** fully-connected layer **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('full'):\n",
    "    W_fc1 = weight_variable([7*7*64, 1024])\n",
    "    b_fc1 = bias_variable([1024])\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1)+b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L3. Output Layer 輸出層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('dropout'):\n",
    "    keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# Readout\n",
    "with tf.name_scope('output'):\n",
    "    W_fc2 = weight_variable([1024,10])\n",
    "    b_fc2 = bias_variable([10])\n",
    "    _pred = tf.matmul(h_fc1_drop, W_fc2)+b_fc2\n",
    "    pred = tf.nn.softmax(_pred, name=\"pred\")\n",
    "\n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(Y_, 1), name=\"correction\")\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='選一個loss'></a>\n",
    "###  C. 選一個loss function, 當作Machine learning的目標\n",
    "- cross_entorpy $-log(\\Pr(Y_{true}))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss =  tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y_, logits=_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='選一個o'></a>\n",
    "### D. 選一個optimizer, 根據Data和我們訂的目標找參數W, B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adam Optimizer\n",
    "- 上週我們介紹的Adaptive gradient descent (Adagrad), 目的是讓gradient隨著時間衰減(time decay)\n",
    "- 後來有人改良了Adagrad的公式, 就變成了$\\color{blue}{RMPprop}$, 一樣是讓gradient隨時間衰減, 但效能較好\n",
    "- 然後又有人覺得optimizer不應該只和目前這個時間點的gradient有關, 也應該和前幾個時間點的gradient有關, 就像慣性的概念一樣, 所以就發明了$\\color{blue}{Momentun}$這個概念\n",
    "- 把Adagrad加上改成RMPProp再加上Momentun就是$\\color{blue}{Adam}$\n",
    "- 詳細的介紹請參閱ML Lecture 9的影片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(1e-4).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='開始執行'></a>\n",
    "### E. 開始執行訓練(Training Data + Validataion Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "# Create a summary to monitor cost tensor\n",
    "with tf.name_scope('performance'):  \n",
    "    loss_scar = tf.summary.scalar('loss', loss)\n",
    "    # Create a summary to monitor accuracy tensor\n",
    "    acc_scar = tf.summary.scalar('accuracy', accuracy)\n",
    "    # Merge all summaries into a single op\n",
    "merged_summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "\n",
    "if not os.path.exists('tb-log_6'):\n",
    "    os.mkdir('tb-log_6')\n",
    "summary_writer_train = tf.summary.FileWriter('tb-log1/train',graph=tf.get_default_graph())\n",
    "summary_writer_validation = tf.summary.FileWriter('tb-log1/validation',graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch:0, batch:0 loss:4.466213226318359, acc:0.0869000032544136"
     ]
    }
   ],
   "source": [
    "#%%timeit -r 1 -n 1\n",
    "epoch = 15\n",
    "batch_size = 128\n",
    "total_batch= len(train_X) / batch_size\n",
    "for ep in range(epoch+1):\n",
    "    for i in range(int(total_batch)+1):\n",
    "        rnd_idx = np.random.choice(train_X.shape[0], batch_size, replace=False)\n",
    "        batch_x = train_X[rnd_idx]\n",
    "        batch_y = train_Y[rnd_idx]\n",
    "        _, loss_s, acc_s, summary= sess.run([optimizer, loss_scar, acc_scar, merged_summary_op], feed_dict={X: batch_x, Y_:batch_y, keep_prob:0.5})\n",
    "        summary_writer_train.add_summary(summary, ep * total_batch + i)\n",
    "        if i%100 ==0:\n",
    "            loss_v, acc_v, loss_s, acc_s, summary= sess.run([loss, accuracy, loss_scar, acc_scar, merged_summary_op], feed_dict={X: validation_X , Y_: validation_Y, keep_prob:1.0 })\n",
    "            #acc = accuracy.eval({X: validation_X , Y_: validation_Y, keep_prob:1.0})\n",
    "            #los=loss.eval({X: validation_X , Y_: validation_Y, keep_prob:1.0})\n",
    "            summary_writer_validation.add_summary(summary, ep * total_batch + i)\n",
    "            updateProgress('epoch:{x0}, batch:{x4} loss:{x3}, acc:{x2}'.format(x0=ep,x1=i,x2=acc_v,x3=loss_v,x4=i))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='算一下正'></a>\n",
    "### F. 算一下正確率Accuracy (用Testing Data)\n",
    "- unseen data\n",
    "- generalize from the training set to the test set\n",
    "- 泛化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict all X and get the accuracy\n",
    "_ = accuracy.eval({X: test_X , Y_: test_Y, keep_prob:1.0})\n",
    "print('Accuracy:',_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Prediction **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 抓出前五筆訓練資料的預測結果 Y_softmax (注意：這個是one-hot的格式)\n",
    "pred_tmp = pred.eval(feed_dict={X: train_X[21:30], keep_prob:1.0})\n",
    "pred_tmp_df = pd.DataFrame(pred_tmp)\n",
    "pred_tmp_df = pred_tmp_df.apply(np.argmax,axis=1)\n",
    "print('predict: ',pred_tmp_df.values)\n",
    "showX(train_X[21:30])\n",
    "print('answer: ',train_y[21:30])\n",
    "\n",
    "print('第21~30筆資料的比對結果:',pred_tmp_df.values)\n",
    "\n",
    "_ = correct_pred.eval({X: train_X[21:30] , Y_: train_Y[21:30], keep_prob:1.0})\n",
    "print('第21~30筆資料的比對結果:',pd.DataFrame(_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 抓出所有預測錯的 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='補充資料'></a>\n",
    "## 3. 補充資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 參考一下Alpha Go的Network Structure\n",
    "1. ** 應用前必須先思考, 同樣的Network架構是否適合用在你的Task上? Alpha GO沒有用Max Pooling就是一個最好的例子**  \n",
    "2. ** Alpha Go的input layer將一張圖擴充成19*19*48的維度, 48表示每一個點都有48種feature(ex: 有沒有被黑子圍住, 有沒有被白子圍住, ....), 這就需要專業的Domain Knowledge來幫忙定義 **\n",
    "\n",
    "![](img/alphago.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 每一層的Filter到底在看些什麼？(or 什麼樣的圖片才能讓那一層的Filter output最大?)\n",
    "https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Homework'></a>\n",
    "## 4. Homework \n",
    "- 玩玩看CIFAR 10 Data set\n",
    "- 李宏毅教授上課影片\n",
    "- must  \n",
    "    - [ML Lecture 11: Why Deep](https://www.youtube.com/watch?v=XsC9byQkUH8) : deep的好處, 有效率的使用data, required less parameter, 破除一些deep learning的迷思\n",
    "- optional \n",
    "    - [ML Lecture 4: Classification](https://www.youtube.com/watch?v=fZAZUYEeIMg) : generative model \n",
    "    - [ML Lecture 5: Logistic regression](https://www.youtube.com/watch?v=hSXFuypLukA) : discriminative model\n",
    "    - [ML Lecture 9: Tips for Deep Learning](https://www.youtube.com/watch?v=xki61j7z-30) : Adam的介紹\n",
    "    - [ML Lecture 10: Convolution neural network](https://www.youtube.com/watch?v=FrKWiRv254g) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_model=False\n",
    "restore_model = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_model:\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, \"/model/cnn_model.ckpt\")\n",
    "    print('save cnn model done',save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Restore Model **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if restore_model:\n",
    "    sess=tf.Session()\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, \"/model/cnn_model.ckpt\")\n",
    "    print('restore dnn model done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
