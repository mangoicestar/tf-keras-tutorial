{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST 手寫數字辨識 (MNIST_CNN_TF)\n",
    "\n",
    "2017/07/16  \n",
    "Jay Hsu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips:\n",
    "- 記得要download data set: \n",
    "[Mnist](https://github.com/Backlu/tf-keras-tutorial/blob/master/basic/mnist.pkl.xz)\n",
    "- 在command前面加** ! **可以執行console command\n",
    "- 在command前面加** ? **可以查詢Help\n",
    "- 什麼是one-hot representation:\n",
    "[one-hot](https://www.quora.com/What-is-one-hot-encoding-and-when-is-it-used-in-data-science)  \n",
    "- 好用的markdown語法\n",
    "[markdown](https://www.zybuluo.com/codeep/note/163962#1如何输入一个方程式序列)  \n",
    "<br>\n",
    "- import PIL error : pip install Pillow\n",
    "- import pandas error: pip install pandas\n",
    "- import lzma error: 請用python 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "-  [Import Package & Functions](#import) \n",
    "-  [1. Import MNIST Data](#Import Data) \n",
    "-  [2. 開始Deep Learning - CNN](#開始Deep Learning)  \n",
    "-  [3. 補充資料](#補充資料)\n",
    "-  [4. Homework](#Homework)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='import'></a>\n",
    "## Import Package & Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import lzma\n",
    "import pickle\n",
    "from IPython.display import display\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def showX(X):\n",
    "    int_X = (X*255).clip(0,255).astype('uint8')\n",
    "    # N*784 -> N*28*28 -> 28*N*28 -> 28 * 28N\n",
    "    int_X_reshape = int_X.reshape(-1,28,28).swapaxes(0,1).reshape(28,-1)\n",
    "    display(Image.fromarray(int_X_reshape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updateProgress(msg):\n",
    "    sys.stdout.write('\\r')\n",
    "    sys.stdout.write(msg)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var, name):  \n",
    "    with tf.name_scope('summaries_'+str(name)):  \n",
    "        mean = tf.reduce_mean(var)  \n",
    "        tf.summary.scalar('mean', mean)  \n",
    "        stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))  \n",
    "        tf.summary.scalar('stddev', stddev)  \n",
    "        tf.summary.scalar('max', tf.reduce_max(var))  \n",
    "        tf.summary.scalar('min', tf.reduce_min(var))  \n",
    "        tf.summary.histogram('histogram', var)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Import MNIST Data'></a>\n",
    "## 1. Import MNIST Data\n",
    "#### 先把MNIST資料讀進來\n",
    "- Training Data: 訓練Model\n",
    "- Validataion Data: 訓練Model的時候, 同步監控目前模型的好壞\n",
    "- Testing Data: 訓練結束後, 評估模型的好壞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list裡的前面是picture X [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "後面是label Y [5 0 4 ..., 8 4 8]\n"
     ]
    }
   ],
   "source": [
    "with lzma.open(\"mnist.pkl.xz\", 'rb') as f:\n",
    "    train_set, validation_set, test_set = pickle.load(f, encoding='latin1')\n",
    "    \n",
    "print('list裡的前面是picture X',train_set[0])\n",
    "print('後面是label Y',train_set[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size: 50000\n",
      "validataion data size: 10000\n",
      "testing data size: 10000\n",
      "picture shape: (784,)\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y = train_set\n",
    "validation_X, validation_y = validation_set\n",
    "test_X, test_y = test_set\n",
    "print('training data size:',len(train_X))\n",
    "print('validataion data size:',len(validation_X))\n",
    "print('testing data size:',len(test_X))\n",
    "print('picture shape:',train_X[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 把Y label變成one-hot representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_Y = np.eye(10)[train_y]\n",
    "test_Y = np.eye(10)[test_y]\n",
    "validation_Y = np.eye(10)[validation_y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='開始Deep Learning'></a>\n",
    "## 2. 開始Deep Learning - CNN\n",
    "- CNN Motivation: 用來做影像辨識  \n",
    "<br>  \n",
    "- 影像辨識的3個重要的性質(Property) \n",
    "  - Property 1: 重要的Pattern通常出現在圖片的一小部分, 而不是整張圖片\n",
    "  - Property 2: 同樣的Pattern會出現在圖片的不同區域\n",
    "  - Property 3: 對圖片做subsampling而不會影響圖片的辨識結果  \n",
    "<br>  \n",
    "- CNN的三個重要功能/操作 \n",
    "  - Convolution \n",
    "    - Filter: 用來detect圖像上的小區域pattern, 當detect到pattern時output的值就會特別大, 一張圖片上可能有很多個區域都有pattern \n",
    "    - Stride: Filter一次在圖像上移動幾個pixel\n",
    "    - padding: 為了維持Filter後的圖片大小, 可以在圖片周圍補0\n",
    "    - CNN其實是Fully Connect的簡化版, 使用了較少的parameter\n",
    "  - Max pooling\n",
    "    - group matrix裡的element\n",
    "    - 每一個group選一個最大的\n",
    "    - 不一定要max, 也可以average\n",
    "  - Flatten\n",
    "    - 把image形狀拉成直的\n",
    "    - 目的是為了做最後的分類  \n",
    "<br>   \n",
    "- Overview\n",
    "  - matrix calculation process\n",
    "  - parameter qty in each layer  \n",
    "<br>  \n",
    "- some tips: \n",
    "  - 靠近input的layer偵測比較單純的pattern, 所以channel設定較小\n",
    "  - 靠近output的layer偵測比較抽象的pattern, 所以channel設定較大  \n",
    "<br>\n",
    "- 參考圖片：\n",
    "![](img/cnn_1.gif)\n",
    "![](img/cnn_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Deep Learning 3 Steps \n",
    "    - Define Function Set\n",
    "        -  [A. 定義參數](#定義參數) \n",
    "        -  [B. 設計一個Model從X預測Y](#設計一個) \n",
    "    - Evaluate goodness of functions\n",
    "        -  [C. 選一個loss function,](#選一個loss) \n",
    "        -  [D. 選一個optimizer](#選一個o) \n",
    "    - Choose the best function\n",
    "        -  [E. 開始執行訓練](#開始執行) \n",
    "        -  [F. 算一下正確率](#算一下正)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='定義參數'></a>\n",
    "### A. 定義參數(Placeholder, Variable, Constant)\n",
    "tips: 把要餵進Model的資料X,Y定義成placeholder, 把要讓電腦幫忙找的權重W,B定義成Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, shape=[None, 784], name=X'')\n",
    "Y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 設定 weight 和 bais\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape=shape, stddev=0.1)\n",
    "    W = tf.Variable(initial)\n",
    "    variable_summaries(W)\n",
    "    return W\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(value=0.1, shape=shape)\n",
    "    B = tf.Variable(initial)\n",
    "    variable_summaries(B)\n",
    "    return B\n",
    "# 設定 cnn 的 layers\n",
    "def conv2d(X, W):\n",
    "    return tf.nn.conv2d(X, W, strides=[1,1,1,1], padding='SAME',use_cudnn_on_gpu=True)\n",
    "    #stride:每次移動步伐, padding:在圖片的四周補0, SAME就是補到conv後要和原圖一樣大張\n",
    "def max_pool_2x2(X):\n",
    "    return tf.nn.max_pool(X, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    #ksize:框框大小, stride:每次移動步伐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='設計一個'></a>\n",
    "###  B. 設計一個Model從X & X history預測Y  \n",
    "Input Layer: X  \n",
    "Hidden Layer 1: $H_1=pooling(f(W_1(X)+B_1)$  \n",
    "Hidden Layer 2: $H_2=pooling(f_2(W_2H_1+B_2))$  \n",
    "Output Layer : $Y=pooling(f_3(W_3H_2+B_3))$  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1. Input Layer 輸入層\n",
    "- do nothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2. Hidden Layer 隱藏層 x 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**  Fisrt Convolution + Max Pooling layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('conv1'):\n",
    "    ## variables\n",
    "    W_conv1 = weight_variable([3,3,1,32]) # filter_height, filter_width, in_channels, out_channels\n",
    "    b_conv1 = bias_variable([32])\n",
    "    ## build the layer\n",
    "    X_image = tf.reshape(X, [-1, 28, 28,1]) # batch, in_height, in_width, in_channels\n",
    "    h_conv1 = tf.nn.relu(conv2d(X_image, W_conv1) + b_conv1)\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Second Convolution + Max Pooling layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('conv2'):\n",
    "    ## variables\n",
    "    W_conv2 = weight_variable([3,3,32,64])\n",
    "    b_conv2 = bias_variable([64])\n",
    "    ## build the layer\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "    h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** fully-connected layer **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('full'):\n",
    "    W_fc1 = weight_variable([7*7*64, 1024])\n",
    "    b_fc1 = bias_variable([1024])\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1)+b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L3. Output Layer 輸出層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with tf.name_scope('dropout'):\n",
    "    keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# Readout\n",
    "with tf.name_scope('output'):\n",
    "    W_fc2 = weight_variable([1024,10])\n",
    "    b_fc2 = bias_variable([10])\n",
    "    _pred = tf.matmul(h_fc1_drop, W_fc2)+b_fc2\n",
    "    pred = tf.nn.softmax(_pred, name=\"pred\")\n",
    "\n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(Y_, 1), name=\"correction\")\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='選一個loss'></a>\n",
    "###  C. 選一個loss function, 當作Machine learning的目標\n",
    "- cross_entorpy $-log(\\Pr(Y_{true}))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss =  tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y_, logits=_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='選一個o'></a>\n",
    "### D. 選一個optimizer, 根據Data和我們訂的目標找參數W, B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adam Optimizer\n",
    "- 上週我們介紹的Adaptive gradient descent (Adagrad), 目的是讓gradient隨著時間衰減(time decay)\n",
    "- 後來有人改良了Adagrad的公式, 就變成了$\\color{blue}{RMPprop}$, 一樣是讓gradient隨時間衰減, 但效能較好\n",
    "- 然後又有人覺得optimizer不應該只和目前這個時間點的gradient有關, 也應該和前幾個時間點的gradient有關, 就像慣性的概念一樣, 所以就發明了$\\color{blue}{Momentun}$這個概念\n",
    "- 把Adagrad加上改成RMPProp再加上Momentun就是$\\color{blue}{Adam}$\n",
    "- 詳細的介紹請參閱ML Lecture 9的影片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(1e-4).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='開始執行'></a>\n",
    "### E. 開始執行訓練(Training Data + Validataion Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "# Create a summary to monitor cost tensor\n",
    "with tf.name_scope('performance'):  \n",
    "    loss_scar = tf.summary.scalar('loss', loss)\n",
    "    # Create a summary to monitor accuracy tensor\n",
    "    acc_scar = tf.summary.scalar('accuracy', accuracy)\n",
    "    # Merge all summaries into a single op\n",
    "merged_summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "\n",
    "if not os.path.exists('tb-log_6'):\n",
    "    os.mkdir('tb-log_6')\n",
    "summary_writer_train = tf.summary.FileWriter('tb-log1/train',graph=tf.get_default_graph())\n",
    "summary_writer_validation = tf.summary.FileWriter('tb-log1/validation',graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%timeit -r 1 -n 1\n",
    "epoch = 15\n",
    "batch_size = 128\n",
    "total_batch= len(train_X) / batch_size\n",
    "for ep in range(epoch+1):\n",
    "    for i in range(int(total_batch)+1):\n",
    "        rnd_idx = np.random.choice(train_X.shape[0], batch_size, replace=False)\n",
    "        batch_x = train_X[rnd_idx]\n",
    "        batch_y = train_Y[rnd_idx]\n",
    "        _, loss_s, acc_s, summary= sess.run([optimizer, loss_scar, acc_scar, merged_summary_op], feed_dict={X: batch_x, Y_:batch_y, keep_prob:0.5})\n",
    "        summary_writer_train.add_summary(summary, ep * total_batch + i)\n",
    "        if i%100 ==0:\n",
    "            loss_v, acc_v, loss_s, acc_s, summary= sess.run([loss, accuracy, loss_scar, acc_scar, merged_summary_op], feed_dict={X: validation_X , Y_: validation_Y, keep_prob:1.0 })\n",
    "            #acc = accuracy.eval({X: validation_X , Y_: validation_Y, keep_prob:1.0})\n",
    "            #los=loss.eval({X: validation_X , Y_: validation_Y, keep_prob:1.0})\n",
    "            summary_writer_validation.add_summary(summary, ep * total_batch + i)\n",
    "            updateProgress('epoch:{x0}, batch:{x4} loss:{x3}, acc:{x2}'.format(x0=ep,x1=i,x2=acc_v,x3=loss_v,x4=i))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='算一下正'></a>\n",
    "### F. 算一下正確率Accuracy (用Testing Data)\n",
    "- unseen data\n",
    "- generalize from the training set to the test set\n",
    "- 泛化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1286\n"
     ]
    }
   ],
   "source": [
    "# predict all X and get the accuracy\n",
    "_ = accuracy.eval({X: test_X , Y_: test_Y, keep_prob:1.0})\n",
    "print('Accuracy:',_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Prediction **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict:  [7 0 0 0 7 7 0 7 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAAcCAAAAABghI05AAAGXElEQVR4nO1YbWxUVRp+oKWQFiio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\nj8Iv/+ddXsOvBT8AJ0+kL8nqYuIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=252x28 at 0x125AFB898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  [0 9 1 1 2 4 3 2 7]\n",
      "第21~30筆資料的比對結果: [7 0 0 0 7 7 0 7 0]\n",
      "第21~30筆資料的比對結果:        0\n",
      "0  False\n",
      "1  False\n",
      "2  False\n",
      "3  False\n",
      "4  False\n",
      "5  False\n",
      "6  False\n",
      "7  False\n",
      "8  False\n"
     ]
    }
   ],
   "source": [
    "# 抓出前五筆訓練資料的預測結果 Y_softmax (注意：這個是one-hot的格式)\n",
    "pred_tmp = pred.eval(feed_dict={X: train_X[21:30], keep_prob:1.0})\n",
    "pred_tmp_df = pd.DataFrame(pred_tmp)\n",
    "pred_tmp_df = pred_tmp_df.apply(np.argmax,axis=1)\n",
    "print('predict: ',pred_tmp_df.values)\n",
    "showX(train_X[21:30])\n",
    "print('answer: ',train_y[21:30])\n",
    "\n",
    "print('第21~30筆資料的比對結果:',pred_tmp_df.values)\n",
    "\n",
    "_ = correct_pred.eval({X: train_X[21:30] , Y_: train_Y[21:30], keep_prob:1.0})\n",
    "print('第21~30筆資料的比對結果:',pd.DataFrame(_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 抓出所有預測錯的 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='補充資料'></a>\n",
    "## 3. 補充資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 參考一下Alpha Go的Network Structure\n",
    "1. ** 應用前必須先思考, 同樣的Network架構是否適合用在你的Task上? Alpha GO沒有用Max Pooling就是一個最好的例子**  \n",
    "2. ** Alpha Go的input layer將一張圖擴充成19*19*48的維度, 48表示每一個點都有48種feature(ex: 有沒有被黑子圍住, 有沒有被白子圍住, ....), 這就需要專業的Domain Knowledge來幫忙定義 **\n",
    "\n",
    "![](img/alphago.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 每一層的Filter到底在看些什麼？(or 什麼樣的圖片才能讓那一層的Filter output最大?)\n",
    "https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Homework'></a>\n",
    "## 4. Homework \n",
    "- 玩玩看CIFAR 10 Data set\n",
    "- 李宏毅教授上課影片\n",
    "- must  \n",
    "    - [ML Lecture 11: Why Deep](https://www.youtube.com/watch?v=XsC9byQkUH8) : deep的好處, 有效率的使用data, required less parameter, 破除一些deep learning的迷思\n",
    "- optional \n",
    "    - [ML Lecture 4: Classification](https://www.youtube.com/watch?v=fZAZUYEeIMg) : generative model \n",
    "    - [ML Lecture 5: Logistic regression](https://www.youtube.com/watch?v=hSXFuypLukA) : discriminative model\n",
    "    - [ML Lecture 9: Tips for Deep Learning](https://www.youtube.com/watch?v=xki61j7z-30) : Adam的介紹\n",
    "    - [ML Lecture 10: Convolution neural network](https://www.youtube.com/watch?v=FrKWiRv254g) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_model=True\n",
    "restore_model = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "At least two variables have the same name: conv2/W",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-b3fcd06472b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/model/cnn_model.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'save cnn model done'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, var_list, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, saver_def, builder, defer_build, allow_empty, write_version, pad_step_number)\u001b[0m\n\u001b[1;32m   1054\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pad_step_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_step_number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdefer_build\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_saver_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1084\u001b[0m           \u001b[0mkeep_checkpoint_every_n_hours\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keep_checkpoint_every_n_hours\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1086\u001b[0;31m           restore_sequentially=self._restore_sequentially)\n\u001b[0m\u001b[1;32m   1087\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m       \u001b[0;31m# Since self._name is used as a name_scope by builder(), we are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, names_to_saveables, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, filename)\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0munique\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \"\"\"\n\u001b[0;32m--> 673\u001b[0;31m     \u001b[0msaveables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ValidateAndSliceInputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmax_to_keep\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m       \u001b[0mmax_to_keep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m_ValidateAndSliceInputs\u001b[0;34m(self, names_to_saveables)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \"\"\"\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m       \u001b[0mnames_to_saveables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBaseSaverBuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpListToDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0msaveables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mOpListToDict\u001b[0;34m(op_list)\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m           raise ValueError(\"At least two variables have the same name: %s\" %\n\u001b[0;32m--> 535\u001b[0;31m                            name)\n\u001b[0m\u001b[1;32m    536\u001b[0m         \u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m       \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: At least two variables have the same name: conv2/W"
     ]
    }
   ],
   "source": [
    "if save_model:\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, \"/model/cnn_model.ckpt\")\n",
    "    print('save cnn model done',save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Restore Model **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if restore_model:\n",
    "    sess=tf.Session()\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, \"/model/cnn_model.ckpt\")\n",
    "    print('restore dnn model done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
