{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST 手寫數字辨識 (MNIST_Autoencoder_TF)\n",
    "\n",
    "2017/07/20   \n",
    "徐仕杰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips:\n",
    "- 記得要download data set: \n",
    "[Mnist](https://github.com/Backlu/tf-keras-tutorial/blob/master/basic/mnist.pkl.xz)\n",
    "- 在command前面加** ! **可以執行console command\n",
    "- 在command前面加** ? **可以查詢Help\n",
    "- 什麼是one-hot representation:\n",
    "[one-hot](https://www.quora.com/What-is-one-hot-encoding-and-when-is-it-used-in-data-science)  \n",
    "- 好用的markdown語法\n",
    "[markdown](https://www.zybuluo.com/codeep/note/163962#1如何输入一个方程式序列)  \n",
    "<br>\n",
    "- import PIL error : pip install Pillow\n",
    "- import pandas error: pip install pandas\n",
    "- import lzma error: 請用python 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "-  [Import Package & Functions](#import) \n",
    "-  [1. Import MNIST Data](#Import Data) \n",
    "-  [2. seMMA- Autoencoder](#開始Deep Learning)  \n",
    "-  [3. Reference](#reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='import'></a>\n",
    "## Import Package & Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import lzma\n",
    "import pickle\n",
    "from IPython.display import display\n",
    "import tensorflow as tf\n",
    "from tfdot import tfdot\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def showX(X, rows=1):\n",
    "    assert X.shape[0] % rows == 0\n",
    "    int_X = (X*255).clip(0,255).astype('uint8')\n",
    "    # N*784 -> N*28*28 -> 28*N*28 -> 28 * 28N\n",
    "    int_X_reshape = int_X.reshape(rows, -1,28,28).swapaxes(1,2).reshape(28*rows,-1)\n",
    "    display(Image.fromarray(int_X_reshape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updateProgress(msg):\n",
    "    sys.stdout.write('\\r')\n",
    "    sys.stdout.write(msg)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var, name):  \n",
    "    with tf.name_scope('summaries_'+str(name)):  \n",
    "        mean = tf.reduce_mean(var)  \n",
    "        tf.summary.scalar('mean', mean)  \n",
    "        stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))  \n",
    "        tf.summary.scalar('stddev', stddev)  \n",
    "        tf.summary.scalar('max', tf.reduce_max(var))  \n",
    "        tf.summary.scalar('min', tf.reduce_min(var))  \n",
    "        tf.summary.histogram('histogram', var)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Import MNIST Data'></a>\n",
    "## 1. Import MNIST Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 先把MNIST資料讀進來\n",
    "- Training Data: 訓練Model\n",
    "- Validataion Data: 訓練Model的時候, 同步監控目前模型的好壞\n",
    "- Testing Data: 訓練結束後, 評估模型的好壞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list裡的前面是picture X [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "後面是label Y [5 0 4 ..., 8 4 8]\n"
     ]
    }
   ],
   "source": [
    "with lzma.open(\"mnist.pkl.xz\", 'rb') as f:\n",
    "    train_set, validation_set, test_set = pickle.load(f, encoding='latin1')\n",
    "\n",
    "print('list裡的前面是picture X',train_set[0])\n",
    "print('後面是label Y',train_set[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size: 50000\n",
      "validataion data size: 10000\n",
      "testing data size: 10000\n",
      "picture shape: (784,)\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y = train_set\n",
    "validation_X, validation_y = validation_set\n",
    "test_X, test_y = test_set\n",
    "print('training data size:',len(train_X))\n",
    "print('validataion data size:',len(validation_X))\n",
    "print('testing data size:',len(test_X))\n",
    "print('picture shape:',train_X[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 把Y label變成one-hot representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_Y = np.eye(10)[train_y]\n",
    "test_Y = np.eye(10)[test_y]\n",
    "validation_Y = np.eye(10)[validation_y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='開始Deep Learning'></a>\n",
    "## 2. Autoencoder\n",
    "\n",
    "** DNN, Deep Neural Network (就是很多層的f(WX+B)) **\n",
    "\n",
    "**這是一層的DNN(其實就是Softmax Regression)**：\n",
    "![](img/dnn_1.png)\n",
    "\n",
    "**這是很多層的DNN**\n",
    "![](img/dnn_2.png)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** What is autoencoder ? **\n",
    "\n",
    "** autoencoder可以幹嘛？ **\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Deep Learning ABC \n",
    "    -  [A. 定義參數](#定義參數) \n",
    "    -  [B. 設計一個Model從X預測Y](#設計一個) \n",
    "    -  [C. 選一個loss function,](#選一個loss) \n",
    "    -  [D. 選一個optimizer](#選一個o) \n",
    "    -  [E. 開始執行訓練](#開始執行) \n",
    "    -  [F. 算一下正確率](#算一下正)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='定義參數'></a>\n",
    "### A. 定義參數(Placeholder, Variable, Constant)\n",
    "tips: 把要餵進Model的資料X,Y定義成placeholder, 把要讓電腦幫忙找的權重W,B定義成Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "lr = 0.1 # learning rate\n",
    "n_inputs = 784 # 每一行的维度\n",
    "n_classes = 10  # RNN最后的输出類別個数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "X =tf.placeholder(tf.float32, [None, n_inputs], name=\"X\")\n",
    "#Y_ =tf.placeholder(tf.float32, [None, n_classes], name=\"Y_\")\n",
    "\n",
    "W = {\n",
    "    'enc_wd1': tf.Variable(tf.random_normal([784,300], stddev=0.01), name=\"enc_wd1\"),\n",
    "    'enc_wd2': tf.Variable(tf.random_normal([300,3], stddev=0.01), name=\"enc_wd2\"),\n",
    "    'dec_wd1': tf.Variable(tf.random_normal([3,300], stddev=0.01), name=\"dec_wd1\"),\n",
    "    'dec_wd2': tf.Variable(tf.random_normal([300,784], stddev=0.01), name=\"dec_wd2\"),\n",
    "    'out': tf.Variable(tf.random_normal([480, n_classes]), name=\"out\")\n",
    "}\n",
    "#variable_summaries(W['wd1'],'wd1')\n",
    "#variable_summaries(W['wd2'],'wd2')\n",
    "#variable_summaries(W['out'],'out')\n",
    "\n",
    "B = {\n",
    "    'enc_bd1': tf.Variable(tf.random_normal([300]),name=\"enc_bd1\"),\n",
    "    'enc_bd2': tf.Variable(tf.random_normal([3]), name=\"enc_bd2\"),\n",
    "    'dec_bd1': tf.Variable(tf.random_normal([300]),name=\"dec_bd1\"),\n",
    "    'dec_bd2': tf.Variable(tf.random_normal([784]), name=\"dec_bd2\"),\n",
    "    'out': tf.Variable(tf.random_normal([10]), name=\"out\"),\n",
    "}\n",
    "\n",
    "#variable_summaries(B['bd1'],'bd1')\n",
    "#variable_summaries(B['bd2'],'bd2')\n",
    "#variable_summaries(B['out'],'out')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='設計一個'></a>\n",
    "###  B. 設計一個Model從X預測X^ \n",
    "Input Layer: X  \n",
    "Hidden Layer 1: $H_1=f_1(W_1X+B_1)$  \n",
    "Hidden Layer 2: $H_2=f_2(W_2H_1+B_2)$  \n",
    "Output Layer : $Y=f_3(W_3H_2+B_3)$  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1. Input Layer 輸入層\n",
    "- do nothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2. Hidden Layer 隱藏層 x 2\n",
    "- 線性(WX+B) + 非線性(activation function)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Hidden_Layer_enc1\"):\n",
    "    H1 = tf.matmul(X, W['enc_wd1']) + B['enc_bd1'] \n",
    "    H1 = tf.nn.sigmoid(H1, name=\"H1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Hidden_Layer_enc2\"):\n",
    "    encoded = tf.matmul(H1, W['enc_wd2']) + B['enc_bd2'] \n",
    "    encoded = tf.nn.sigmoid(encoded, name=\"encoded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L3. Output Layer 輸出層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Hidden_Layer_dec1\"):\n",
    "    H2 = tf.matmul(encoded, W['dec_wd1']) + B['dec_bd1'] \n",
    "    H2 = tf.nn.relu(H2, name=\"H2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Hidden_Layer_dec2\"):\n",
    "    decoded = tf.matmul(H2, W['dec_wd2']) + B['dec_bd2'] \n",
    "    decoded = tf.nn.sigmoid(decoded, name=\"decoded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "with tf.name_scope('outlayer'):\n",
    "    _pred = tf.matmul(H2, W['out']) + B['out']\n",
    "    pred = tf.nn.softmax(_pred, name=\"pred\")\n",
    "    \n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(Y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='選一個loss'></a>\n",
    "###  C. 選一個loss function, 當作Machine learning的目標\n",
    "- cross_entorpy $-log(\\Pr(Y_{true}))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cost Function basic term\n",
    "cross_entropy = -1. * X * tf.log(decoded) - (1. - X) * tf.log(1. - decoded)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "#loss = tf.reduce_mean(tf.pow(decoded - X, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='選一個o'></a>\n",
    "### D. 選一個optimizer, 根據Data和我們訂的目標找參數W, B\n",
    "- 試試看adaptive gradient descent(adagrad), 這個方法會在每個步驟都根據前面步驟的梯度來調整learing rate, 大致上的概念就是一開始走快一點, 接近最低點的時候走小步一點, 當梯度值突然很大的時候也走大步一點, 看一下李宏毅教授的上課影片就能理解    \n",
    "<br>\n",
    "$W^{t+1}=W^t- {\\frac{\\eta^t}{\\sigma^t}}g^t$  \n",
    "$\\sigma=\\sqrt{\\frac{1}{t+1}\\sum({g^i})^2}$\n",
    "<br>  \n",
    "$\\eta$: learning rate  \n",
    "$\\sigma$: 過去所有梯度的root mean square  \n",
    "$g$: 梯度值  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.RMSPropOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='開始執行'></a>\n",
    "### E. 開始執行訓練(Training Data + Validataion Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, batch:1000 loss:0.20270146429538727\n",
      "epoch:1, batch:1000 loss:0.18921609222888947\n",
      "epoch:2, batch:1000 loss:0.17552180588245392\n",
      "epoch:3, batch:1000 loss:0.16751596331596375\n",
      "epoch:4, batch:1000 loss:0.17940010130405426\n",
      "epoch:5, batch:1000 loss:0.16222664713859558\n",
      "epoch:6, batch:1000 loss:0.1655009686946869\n",
      "epoch:7, batch:1000 loss:0.16602760553359985\n",
      "epoch:8, batch:1000 loss:0.17098791897296906\n",
      "epoch:9, batch:1000 loss:0.16780605912208557\n",
      "epoch:10, batch:1000 loss:0.17227838933467865\n",
      "epoch:11, batch:1000 loss:0.16715852916240692\n",
      "epoch:12, batch:1000 loss:0.17570552229881287\n",
      "epoch:13, batch:1000 loss:0.17296543717384338\n",
      "epoch:14, batch:1000 loss:0.15924768149852753\n",
      "epoch:15, batch:1000 loss:0.15998207032680511\n",
      "epoch:16, batch:1000 loss:0.14498353004455566\n",
      "epoch:17, batch:1000 loss:0.16198484599590302\n",
      "epoch:18, batch:1000 loss:0.15130186080932617\n",
      "epoch:19, batch:1000 loss:0.16509881615638733\n",
      "epoch:20, batch:1000 loss:0.16471390426158905\n"
     ]
    }
   ],
   "source": [
    "epoch = 20\n",
    "batch_size = 50\n",
    "total_batch= len(train_X) / batch_size\n",
    "for ep in range(epoch+1):\n",
    "    for i in range(int(total_batch)+1):\n",
    "        rnd_idx = np.random.choice(train_X.shape[0], batch_size, replace=False)\n",
    "        batch_x = train_X[rnd_idx]\n",
    "        #batch_y = train_Y[rnd_idx]\n",
    "        _, loss_v= sess.run([optimizer, loss], feed_dict={X: batch_x})\n",
    "        if i%100 ==0:\n",
    "            #loss_s, acc_s, summary= sess.run([loss], feed_dict={X: validation_X })\n",
    "            updateProgress('epoch:{x0}, batch:{x4} loss:{x3}'.format(x0=ep,x3=loss_v,x4=i))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_tx = test_X[:20]\n",
    "decoded_imgs = sess.run([decoded], feed_dict={X: batch_tx})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAAcCAAAAABaa9rXAAANrklEQVR4nO1aa1hWVRZ+NbwiYoKl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\n4rfDfwGU1DrQoqFuOAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=560x28 at 0x111D0DD8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showX(test_X[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 784)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_imgs_1 = np.array(decoded_imgs)\n",
    "decoded_imgs_1 = decoded_imgs_1.reshape(20,784)\n",
    "decoded_imgs_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAAcCAAAAABaa9rXAAAY/UlEQVR4nO17aXAkyXVevsw6urr6\nRB9oAA00bmDuY+cmZ7nc5ZIbpiiJNIM+ZFtiOORwhEIKO+yQHY6w/UPhCP+x/cMKB2mLlMIHKXkl\n8dJSy509uNyd3dndGcwBYGYwmMHVjaPvruqj7kz/GKCPqp7VkpREyaH3B0BmZeZ7L7935MsEQn9D\nf0M/BsHPmoG/zgQIGCDEEPtZc/KXRx8VMADs/xOtABF4ZOn0p58IgJcSw2ZFberWTz/dXxPiPsI3\ngIVgYsioqUrT+gmWAEAM/VUxQoyFUDKhbZdbP8YWAyDktRfA4uDJcyPKw/XdfK1p/7icwI+rk33b\n/hkr8s8GDGAxkrnwVEKuLV25X9af8JXgjyslryyY80cGx4iys9uwKXUpHRBiCIDHYFv91OCTI7Xq\nk/cVCKZOzzgAhD4MB4A5ITg6H5WKVP3IsRg4f3piBLa3cnW7e3IALjhz/ignK1mbAuAPYdTjnYGT\nx0ZHrOxmoeV4xwEZPDr7zUpvB/j942PJAWn7UW637vRHDTCEEMIY048GX/D7hzhNreofGj0AIcDt\nvfuzAcPzodNPD0/KrDJ2Ht00++sFPvkvll+setgkQvzYmYlBQVm4dl8xEe2YBxB/gG/pJsf7hoKN\nfKGP64LT/3rttVc1TzMhBNmIQXjELlQ74whGHGc7FjtQnHscYN4XGJ46PAAmGtrA1IW1g0wEoEdE\nEOOXPnc0YCjZN99db3QNAswljmV45d7dPBVbmLoXxRyPbQsx8If0ptE7pxA788WTsla+80fLiu3R\nKMiXf/XYuV/tsU0YOHM+cyyOm8raDz9Y022PhFgM+5otEzMuGjErykdCTPIfv+CX7c3XFnfLdZ16\nlQZE5CmzCQG+pTuP2ziEEOJ9Aocl3qJNjSGLETCdDiMkEI9oRq5VQREWjqn9ASOcnC9WHHcrEeNH\nn5sekBx+vlZsWl0bCWJ4JONYYPOGkEluvlf2agCE+fSG6hYcsBAIx0VbxP7x9NYPau0OaaApjrLJ\nTPlRvlE03aMAISDiQGryxCDotmojgnu6OV6WEAabEWapWjcshNRnPn9EdjQ6FZ/5znKtbdsAjIh+\nUl5c2NEtkO1mD2AAOH88HgM7QLiwtHS9lyFu4Om/f9Jv2MLUp+mtlse8mZ066Z/ubfONPnM64leL\nWTt+SV3zYowLjMwSy6CyieOR3PVmm0+BZwwBptSmCDEEXbE1+Iu/EcbgpMe0IfrDf6aCa1bAfDCZ\nGPBRvlTSq8V9pXAIId/IxPyhFOEIaqFWSyPCzh+ttC0Xc8jeYSWnrA3PzvuLuf7Q9T0j0JxbcCD+\nzDOTktlsQvhovqi3vTYAH5mZSxsWdjQazQSDK6SPU/B9OjpVcwlBOCEyOj4s8SAMDQWX3+6sJTiR\nqbPT5wKqom78j+Ve7AIAAPHFZk6dGGxtb+s+ZnLQdjGAiRBKzw+HmI3lqJy98p7aQQxEzv+dw4K+\nkzVC6U/4v3mn0UY2A5Bke/vOeh1h3kcto0sEIGJwaHYiQYJ+f0i04ytKDzvSzOdPkdz9nBg8gur3\nqTstYSgTIGJvI0lVbhnlpSJKf/FQdfGBx5uFJw5PCMjiwPZH5dHN/D4zEJ9Lx9ORFge6wppGS7BK\nyzvG/qjAr4R5ZG++vHtpRv6F5f9q9kZVIEJoeDYToTxymhu3lX3McwgB8Y1/7NQgAUYty6Y2ce6t\nZ9UDljBDzQLN0TzVxiKhlVuoLwkzxtses8bi8MUZvtWsqsmhydKK0om8mEscPxGsbpTqTmAkFa1J\nxJtSYP9J4HhXIMdcaPrsIUmt2hYflzS9ozgmTDzzTDzQyifHjpN/U3PzQrBv4MjZkzGrsJHjo47D\nOKs9Jx+cOHt2TNQrijM4TIa09WYbbyCd+NIhn3L7/aJ0SEqeriprXX1cOtZ6sFqwOZH3B5o9ByUi\nJk9dTNsVw0ChCAi9gZ8bev4EfvTGkhY/kTpfLhQcTyI7T2C3V3KueZWVadkMyo40KGC3QfCRufNp\nO5ttMn48EW0EDvRJ4jMfn0+HEHNM29EdCytLqZf39o1+PGEh44PffBjcSB2mx0e3nN4UDfPRuYuD\ne8ViID6eKjw6YAQh5Og2IbZhtZSyjrToFB8Jk/Y4ZLcsSyOm4tC5E35v5HhMJpd9zZOGCMHZU3Iz\n96jGNHl4KMDaiROAMHhsTF2/nWtCNCwIqEq9eQeEwkal6mpkEJg7PZBbXNU5NEkLXSkx4UODpJV9\ne/XipfTp2Q88WaYQmpif9JW2buxAAtVVhtsQ5YJHn/vUMMtvrD+EI9FBUSadcdzEC2eC6rt/sArD\noM37RifyrTYrKDAl5u8WNUZFX4Jr2lpXKsq4wacOO4sL28j38U9ytoG6COTpp2Plqy9ti2OJwMzc\nSMWTwhKZofu9gLFXgZrMkMcv8NmC96SEI4fn+LvvrygQZvMiaRwMxpwci8u4pVnUorrKxyNHw2sH\nCyrvz0ey/3HZsd77/X+YSB/b7UEhA4aDhycLS6uV2OGxoUBbIwghR9l8AK3F260qtaTYic9OW+tt\nCZnNWdQykG0hywm1VDen++QX5IJbCsxHjwSVzYebFWqOCVHK2L4YgPDA0bTz/vVHDZPjFSToLfcB\nCiFEZnzyqhswWBw+LBWuLuygDHP0Va0TOnQTnNbC95cNFB8YeuZO72kOOFGKJkJ2ZePGQzoyIq42\n6QFegA+d+sLlGF1950dVJIaflktrnWQMh546F9be+dqyThr1Ok7iw/cr++bJMBeP2cvrLQcTaWhO\n4FmxE66ACx055Nx86ZFCxqomV9G7pSPBIxPW0pU1U8/x0lByct3jmv0yY5FehegGYJH3zX3uBNS3\n3AMQlqfn/Iuv3FAsjtawpLVTLWjsFgbU7FurQcI1wRc7fShmxg4MYue3P3lm6Y7DcBxTy4exe1Lf\nSKa08EFRN08AbcdNDiFkK0vmq3s7GmUI+FLEwOxex1tQGzvIQBi4YEZt6u5Z92k89K2WqwkwPxTR\nC7tb26oDJ8BHuuyCzxyS7t7ZrJmMx0GRg36Hdf6ypLyuuj2FfDTTfOdHe1YwNe0r5Mx2NzVarWbu\nrev1YD2vhc9FSt25FkO8GIrJZkW9+UhLTB2tAOD23oqjT1+KN27+8YLCS8NTKd/anXZiD1zs9Lhz\n73eWFUZsxzBOT0yNbnQYTIYbDxWKhcj4uWFGILJVaVcH+JHzkVsv36rTUGwmatS6AQMkeoEU39jS\nKalnhdjM2TuK+7QgYYRWe5schrkQP/HspYmyIeEYNXs0gwePDalvL5RMRPhkhDfUA8CwyoJ9N3tz\nzwKEMS9EypOjG/ZBp3rT0a5rPD/xjwajTEnEWL17RYbludDy0k4LCRE53zxYjkOIIUddOqhVMjab\n4N8sdnFDKQLAmAQTYW274TkJPVbCM/i7nmyY80WCjpXfqRmsqejdlRYITQ0Z97YVG/hwbNAPSp9I\nB9Hz5N4t96QklpH2VmqOkLk0iR9ss04go/rqRDVnoFgmCHYrUuvx85gPxxIBoXx/0wpmDidqlNl0\nP7HF0RPjUFr81qJqgXDmUih/ZbUNQ/BljvPVP1iqWcixHR2lp9PJdiQDfpDL7zIiDhw6MiUa0Zkx\naqj76gF5ZlDbzBlYmrl8LFC83yUGADeURg+WSwa2HJNOzIylHqFeAkGgzqNelTAEvlZ4YjSm5LLp\nn9eQ8i2l6wNpeo48uK9SzEdHDoXZhnHQZ+uV5cXtfYGA44xRe3HvwBtQs3jnoZie/+UxRMlAZoxo\nveqWBqxi0QJxeEgqKweq5h6PbOuIP35ytPyayXpSCoZADCXTaOPhE8owwgv6irsNsBCKQGmzqjPO\nJ2qtZqeLxGZSew3w80QcGc1E9KyNwFPGmBynVzwRkB+fCutCPOR/9lyiuKwB4HYs00v5cDTOP32Y\nN/VidKuXFXlkJJFE20WcHDk7iaq1VnscJ0u4Vr9WFgPa1OVPjelX36h24pw8njSW3q0ZDNlgWYWa\nEO6kPhAcFRrEL0QzJ8ckqlgRNrZzkBGDNBp02JDIQp++NITv57pSNIa5iaC++LBBHQdhMWdEBj3W\nIoqOs+05bFPDeKi/27C0mbGz4Zu3ljsmCIGxFFIhbiN+6uhMYPeugeCxP2fUynaycV7+26HtOxtt\no6f1VTR05lK0iitRei71jXyzp/AZSPE4bCH52IhIG3R/xsf5e2fpzKcv8dfWHXdN1hefmz7ErTxo\n4r5FsctnV/KeRioGUntbRQthEGTc7Er8hGhKDE5Uq6IUG07NBtSWwzynJPwrw/UrbniCLypxwek5\nOXVsSsyWEGFOR3rzUfJIfOBiuFEpbouYs7sqeEJyOjzq37Xj6WTmqJwrGLQdWmk1u10tFpqycOTi\nx6fh9u/udCppRBwVq9f3TMYYYgyZRCSdMxJJp3h/lEQz82ln19pkw1I0VDnoRLYhTnJyMDqSDlQ/\nUBm0VQwMj3GNuzUHMYpAd/z+gFt2logLFY8+mYHqD7d0xqPVKPnsqX/yn7bbgQ5LYQLxE0aA+IdG\nM/xOnqL9c1THkyKE+NiXLrO1e0pbPqYYnEbsBSOZaJRR4rOx91tVu+NlfMg3OD0VTM6PBDiDOI9h\n4qr0Rj/1TGLz1SZzAYZEx0+ciu5qmga4X0XwP5AbhrsNgZgJ5YuKjjAEBax2YgRg8OHw5YwS4CUs\nD/tsrU/OK34GFx94FhLscmgoGJYgLqH1FnBdNXDmbN/60pww4muUlPjIutJ02AFgyMCROTnu1OKp\nQHpgoFg2fWI7a7JrKw7Y1ZYwPjk3LN7/2l296/TvS9HSlv2YO8ZwKtJo5xsQHJNxMASDk2k5V8yV\ngkOkU0yi2vrGZCbtx5ok4bUHRs99Nh/HDcV6LDGVQ3zDI2VAQLY7JUTIhpaJGcKouKbWLl/Kfb16\nEHnANBuB+RQSdFsYCWub9Y4LYJ0cggxc+qcB5fpOV8Joa9i+XtcDZwJXb8iJ2V/6ucUrKx126pvJ\nmVAgyIXDPhWRfQj2AkY6+Ytz9L1ld/ERB2ZOZBLVvA2I4T4XifF585ve4iOR53B1u2ExngsktWLn\nYpw5dHdAjg5YgFQlIOLSju1F4akovdF0NyJ9/d2yLMg6J/Hlpb2W0106cNS1axfMXbLNzU9HzQXS\ntNjjwAPi6JG0xNf8k+GQzGma4shK2ySYtZ1HjKHoqDwTrb/4ltLFCvP5GvXGPpqBi80Gd/IHG0BC\nvCKSMPbLfG03V7Bk5Fht9DL1Fj0SEyWHDviMDzaNbgMEzoH6fiUW+1JBU3fLDiFEDd4tOkMIbMoA\nMYZWv7r+/LMbP7D2mWHG3dBoMgoWNJ0w0e4qfQwQ4dClfxkzN7/TXaunDJHyNc1PvvHA8nGbqWfP\nDH598WA9e/dWdHDQLxcNieYPbgZ6AANc6G+d4Nde3XQ5GOCiqYkZs1K1BUmnCFG3A/o1Yf2ah0Hg\n0wnWapkUUGAyvrfTuR5mTu16MREIYK2Usy5MwUredM+I8L8i2u968mjWeJD1RVID3OV5+9rVHYPa\n3eB11CW2ww9vyPzp4+KObtn7s5LQbCbMNXR/OMIjYltNtdrQDzI/RlsIAQi0eXLQeecHxe4qGmuq\nmo4epy3ARc7P0pXSgeKwr1XEtuQLYU1VzWA0GlRr2oGITN/IvxWMSs6Zi3jr9UJ3hGfMthzL2lfs\nyHF+Z8+TrczaOM/csR+ABPX9a0Jj72rwc88u1Pa7qH43H4uOSM0qnT1m7S0anh1CCPhjf3faLn5l\nz1VtQarl6G+UdWbghzeeS1z6dked1YXK+FB4Tz1/tPqoeWCaPR5GOP2ZQOvFHxquO2AuOHp2Plyo\nkrjPX8na2DSNHo/AfZ58x3tHCDgiEd4vGlz08DmfstnoINsuLD4weFkyd1vJ46R+r88FnHwBby16\nzIQaJQDuUXjieV/tT+42qevpkrVhMjC2QquXB6I+igD2vWhkQOIwBimIaUCgte37JbNzIGAIIQZM\n/thxPve/VntEZ2alyUcidUoB8+GLvxTLLrZv5IFouzhwysfxEJwY4qI82y21DjaDOc0WYFGMfDxG\nP7hp0C7xANlFi49yDkOIxC4ctW8W3CdPyHDI8fhcIEI42qoxZjLEbHVTSEbbfDZ39gBLMmiBId5Y\nyZt9zrIk8YXTZOfF1ys9VoiB8wcagkMZoqyxyqRoshNX9Vzp7kC47D9H6iXLod1J7z5Ffi1lv/6t\nsqvyiAODZ9IB5IS4kH6opBSN6qbTUzqKJOkfenacIWrrAd+oYoSmL6bqW1tdILMrKqKAsM0wk3Bl\nz/K60HN+dKWCPEQRQg5FgQl08+2GS6dAkZGjKO804DZnDN5nvPlYeCJohZTMB/yc4xNpfvnWbstx\nv6cQTn0hqP73t4yeZqpnj8DUulpzMB878+WZ5ntXW+3kQC0Ig+lhP1i6lrR9qLW+WegEF4YYchxn\n8JJYfrHajRfEwFwt+lLhqo1w+NgnfPev7Ll1R3RKi566OUOEjIfV8nbFRpjjPpYiA22HZtsIIRUD\nWCFoLbXcZxaEEIh/7+lQ9eofum95MU1cgN3NloMYgsNxPsJ3rh0otVsKwekEVivtpKEbMOTZaXHn\nd9ZM1z4IUmxqKIRGfNTgaUvZfpTXeiF1FtbX3AwihOztXCZ6VIT03CjLLtW6vYh1oA7MElip2B4B\n8T/Axuv9az6IOvzckP69ktsGGULMRMhGxsZbfiGOjfYBwczJxMZ+zjaQXXjrzWzDoa5NgvQvx9D7\n/9tVJ6RGrpwcP+fbNkj8/OfG0YPvbbZ5cmqWxafiEZnqmkH1wsriasmFQoanjrPby+4XL/bincPH\ndx41qHzki2PqW4se58xWVFn2HBsZMuvkSLJ1521V8Ps/9YJg3OsEeYQQchzAwiRpbLotCSGE8JnP\nZpyF/7NiuDaX2TQ5Aa13co26OvZlGVV7LlWY42BBGmUVrY2zLsDA5G+MmL9/relaDfj4zACPbE1S\nGzzOb6xtFnv3lzwHa31KtczOLqbSnzjGhgN28eZy/xduOJlEWtMroPQU7nOJf8DQ4CW8+W4fEzz4\nxfpgJrWtt0FhVTea2ggvii2da26+t2U4Lo8GEP7nx4S13/K81jIebYyOTz61W49npsPa7a9e68hJ\ndUOvqw8nk4RTjMb62kZJd3stHHzBr73kLlYzp3R99sLAyrZ/4ql085WXih4xMXFw3nt/72CWSE/5\nJw8v03PDCe7eV7Ie1ZDZMVTM93mNBmP/9hQs/ufr7n1ihPDFySltZPkB55zPOPUfFNxf4KGAvddx\nIh3AQPy3JtH9b3g2lto+WjJIVTG2m4jVq0W12Vu+k2a1d/oUZ5hTejN5ZmKCI8rmm2+6re9AwskQ\n1lvernDYyVX7lnwQIqG5jL1U69/5mOXaeycdsQ0hp+5Ut32CjBuYa9YLOnUDFEd//XnI/vZ9t+jM\nKr4ZTU9OGVgCW/3R12506ZuayFS23vGLoqCbtGE5TvuubJ9AHHkKKqsePDjKO8c+8/zTLIho4cr/\nXPf6UWLp9qjskZ459XuR+cDs8HEaijsvfzXnfXQmnQ7ZDc9NA0KQ/vfH8e5/ueNxZgihxnWhFBhM\nh8YG44Vr2y+ZnmUHBGrafQAj/eYnReuVsne11u31t3ytpk0NB2OBM/TeEAnhB/au2O82yMhepTMy\nV7nxxnpe6+8uyIwfGt4uCNw6nn0CXkCIXIjqK+aHPG5l+r0jwaHiQeCkht0sMwyU8TxYusNcuTIW\nf/7L8t4brxieGWlr9fvcmRGJN0oP3v5urkeZDDHkmPsPXQDA8+oXS5fSdGvP+wbTKX7PemY44JSW\nr3y/0Od9EV0sRBs1r1QOe6huzB+NthDbev97ec/WIuSfEO2S+w0RQij4688J1kuLnooPYg5PUbae\nicUHSO52bm1j1a0ERoNIb3Vy1jZguEMXRWfh240+22AUiwe/guYt3CnfcEpevDCH0d1X3w/JplpU\nrT5RFSGEgJTz/hVvuQXtfSV2t9Z3CMKcH+3t3fnwZ/8mOUMfHDg1ZtuAACMAx0KOp+YDOPVzfH3h\nv1W8M1Kz8sHDZCQpquWt/IetyBggV30KOHmwpS2W3IhgDLVuZ789GjZK94tav9e09o1/d+xPFe9q\nzFHqG6/5RAdo01uIQAhhf6NauFb3dPDjc5z25tfz3hGMtrKFdf/QQo0Gs9VQxftqEuHiHttwPB4G\nCOyMqt/N9o8cjz9hCDHkmZE1Fvp/T6nVyKMPfeYOzu0/1V/2Pvtk9VfYE7fHKi6whZvGhwEG2Ja1\n2J2ZM4QoQhhTm3mxywUL9zZ+L98vx2Z2o+FNFfqR91zCjJ3V0rf72Ds1zdrae0+eyq6+/toTuii1\n9f2N6EOY3sX33/BEeCBCoVz8v5v9vDxDtg1q+QEYlDq7feYEtPTHxo/srr/3fwpTh2fvvt3Hyv4i\nCYjkN+pPOA09aQwigmB4yqO9ROK42i9K9gtzQJInWht7fTz8T0WAuECi2e91+18YgS/K6ronyIEw\nPTW8tFj/yfYWCyLVO1J0Tm+YwEf874Q/T4IPc0B/afRXg4s/B3qCIBzBzJuh/UT0/wD7rxVEtnGz\nEwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=560x28 at 0x11350DD8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showX(decoded_imgs_1[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### other picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAADA0lEQVR4nAXBz2/bVAAAYL/nZz/b\niZ04id3EbHRdRju6IiG0DkE7CXEgAtQDHCYOiE3ihMSBP4ALR45I3PgDOCBxACHxS0u3ahIw2pQB\nS7eVrYnTBJw4iZ3Yjt/zs/k+8G6AgtPXX5q9+vu3T5vPs8dT4dw2bv3s+mRwCjMj4s/1m3zaH2Xc\nkyM/TQzM6VgSi+eXEMWm5Khi3wssS98bymI5PkYzODo9K1lQzm1Ww8hYjYbRfV01pW7n5hFs33wy\n+tMX0HzfSkYVvd771OpfKDgLIx0NiANHZdqGyHkjOpbhtPmVPFUJSzxDCQ/inCZ6WI0QN6fO3rWV\nj+EZQT8cdhSgC5KYIlzAM4xOns2WX3Tyf9RVTZw8OuamhbyoKQ4zOTRGN9R9FxwuvrzdrPGTx+Vg\nIfseMAKd46UiLLnubgG/89ZzK/X+xoelOJOAyE9hYoe4DB+y/JVbdXVg6eLay7mTVFPkOKMhONnt\nEvD+spm1toJflLQaRz8O8yUyLCLPr+Xn+RKsckmyzg56D0KCtq6OF4pUwJSPNMHJKKp1vFzWdzBc\nNF+jA9QgVbuN+RWG13sp5OzZMLTkmEuU3z4TP0Ky9cx2hgTIxWSAWsmYmYxQgqVS/u2lX0fdp/CK\n40mLNDeH4+9Gdrp8BijaC8nmwx/6F3fKyEAMpgkmcO0L6t3fPU0ewHFi94OFHyaRrRU6Hlcow5mq\nMfL51xOpeVgcu4bR/t6t1XuCQGJUAQCsZyfb8jfZKxVZ5c8zFxTWWp+swkAwOdD46U3Vv/b3vctp\nY+/IPFvssED6h04HQWbIKKk6FxoV23gPBxWEi2gJLk0OVBJASlUUrR3s1KmyE8+GoTzdDy9RRu5V\nEYpkkaFsPov0u1c2boFKBt1abRI/+reRtKkgpAz6c25y+6/LqdTjWS61yxWMi3J1VVUmEUBjfPGu\nez1NLW8d3snRqaCqrTsaBxIqR4iDcfiBESiXNv9bDbsbJVG1PZK5eSDEDkQcuKp3yWyuKL65VRSZ\nTBgVLMXhJuP/ARdyhCfIU6xlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x1135D6A0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "im = Image.open('img/ae2.jpg').convert('L') #Can be many different formats.\n",
    "pix = im.load()\n",
    "pixels = list(im.getdata())\n",
    "#width, height = im.size\n",
    "#pixels = [pixels[i * width:(i + 1) * width] for i in range(height)]\n",
    "display(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABuUlEQVR4nKWSW2/TQBCF5+z67jju\nhRTFVXohqgRERVTKA///JwB9QKACrVKlJDiX1k5s7+7wEOxE6hvM43w6c86MhuhfC887AMCan0EI\nNwyjoJqmhWIia2cGpHd48bp/OPv+6bog2kIA0o3PBlcXsZ4Udx62ECAp/bg/fN/zymVekRCox4Ig\nLDfqvrnqu7PRzGibBIG4VkrLCzvdffz6POL9QhkCc+0JaUkvjPLxl49lEpS/M8PbQEIA0n68+XY9\naffaT5PSNIEYIEjHTidfH/goSaalAXb2FFaU7KU/UxH2zqKi2lyo9rTbrwZyrltRd3iSz7OKuVFC\nto4/nD54Pb97PAhnORtqPCHD5PKytXqZRAftvSxjKXQDhXv0dthZ6jj2bM7Vgv0nzUwkiEjY7fN3\nJybNSFhKlUYZxxZEf6H74vSA8kdueSIMArPOFXGdVvodTxdoeZHPRuaj8SyvmgsJJ3JUHvcI5Wqx\nVLc306xoAgE8n0vXFuvl+Md0Pb6drlSzil7flZkTRH6e3t+XvFysFXP9YLCD0JdCVcpoTVax2jg2\nDwZAEkDMIKM3up3vA4gAZqIa/U/9AayZyz/JylyHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x1135DBE0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pixels = np.array(pixels)\n",
    "pixels = pixels.reshape(784,)\n",
    "batch_tx = [pixels]\n",
    "decoded_img_test = sess.run([decoded], feed_dict={X: batch_tx})\n",
    "decoded_img_test = np.array(decoded_img_test)\n",
    "decoded_img_test = decoded_img_test.reshape(-1,784)\n",
    "showX(decoded_img_test[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LOG_DIR = 'tb-log0'\n",
    "input_data = train_X[:10000]\n",
    "input_y = train_y[:10000]\n",
    "if not os.path.exists(LOG_DIR):\n",
    "    os.mkdir(LOG_DIR)\n",
    "#把圖片的label存到metadata.tsv\n",
    "metadata_file_path = os.path.join(LOG_DIR, 'metadata.tsv')\n",
    "with open(metadata_file_path, 'w') as metadata_file:\n",
    "    for row in range(len(input_y)):\n",
    "        c=train_y[row]\n",
    "        metadata_file.write('{}\\n'.format(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save variable\n",
    "Input_Var = tf.Variable(input_data, name='Input_var')\n",
    "tmp_aevalue = encoded.eval({X: input_data})\n",
    "encoded_Var = tf.Variable(encoded.eval({X: input_data}), name='encoded_var')\n",
    "decoded_Var = tf.Variable(decoded.eval({X: input_data}), name='decoded_Var')\n",
    "\n",
    "saver = tf.train.Saver([Input_Var,encoded_Var,decoded_Var])\n",
    "sess.run(Input_Var.initializer)\n",
    "sess.run(encoded_Var.initializer)\n",
    "sess.run(decoded_Var.initializer)\n",
    "saver.save(sess, os.path.join(LOG_DIR, 'autoencoder_train.ckpt'))\n",
    "\n",
    "#在config裡面用一個embedding關聯 tensor & its metadata\n",
    "config = projector.ProjectorConfig()\n",
    "# One can add multiple embeddings.\n",
    "\n",
    "embedding1 = config.embeddings.add()\n",
    "embedding1.tensor_name = Input_Var.name\n",
    "#embedding1.metadata_path = metadata_file_path\n",
    "\n",
    "embedding2 = config.embeddings.add()\n",
    "embedding2.tensor_name = encoded_Var.name\n",
    "#embedding2.metadata_path = metadata_file_path\n",
    "\n",
    "embedding3 = config.embeddings.add()\n",
    "embedding3.tensor_name = decoded_Var.name\n",
    "#embedding3.metadata_path = metadata_file_path\n",
    "\n",
    "#embedding4 = config.embeddings.add()\n",
    "#embedding4.tensor_name = Out_Var.name\n",
    "#embedding4.metadata_path = metadata_file_path\n",
    "\n",
    "#embedding.sprite.image_path = os.path.join(LOG_DIR, 'img/mnist_10k_sprite.png')\n",
    "# Specify the width and height of a single thumbnail.\n",
    "#embedding.sprite.single_image_dim.extend([28, 28])\n",
    "\n",
    "\n",
    "\n",
    "# Saves a config file that TensorBoard will read during startup.\n",
    "projector.visualize_embeddings(tf.summary.FileWriter(LOG_DIR), config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!tensorboard --logdir=tb-log0 --port=6006"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
