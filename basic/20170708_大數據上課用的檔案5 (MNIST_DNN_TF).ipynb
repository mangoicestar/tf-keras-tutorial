{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST 手寫數字辨識 (MNIST_DNN_TF)\n",
    "\n",
    "2017/07/16 update tensorboard \n",
    "visualization  \n",
    "徐仕杰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips:\n",
    "- 記得要download data set: \n",
    "[Mnist](https://github.com/Backlu/tf-keras-tutorial/blob/master/basic/mnist.pkl.xz)\n",
    "- 在command前面加** ! **可以執行console command\n",
    "- 在command前面加** ? **可以查詢Help\n",
    "- 什麼是one-hot representation:\n",
    "[one-hot](https://www.quora.com/What-is-one-hot-encoding-and-when-is-it-used-in-data-science)  \n",
    "- 好用的markdown語法\n",
    "[markdown](https://www.zybuluo.com/codeep/note/163962#1如何输入一个方程式序列)  \n",
    "<br>\n",
    "- import PIL error : pip install Pillow\n",
    "- import pandas error: pip install pandas\n",
    "- import lzma error: 請用python 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "-  [Import Package & Functions](#import) \n",
    "-  [1. Import MNIST Data](#Import Data) \n",
    "-  [2. seMMA-DNN](#開始Deep Learning)  \n",
    "-  [3. Reference](#reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='import'></a>\n",
    "## Import Package & Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import lzma\n",
    "import pickle\n",
    "from IPython.display import display\n",
    "import tensorflow as tf\n",
    "from tfdot import tfdot\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def showX(X, rows=1):\n",
    "    assert X.shape[0] % rows == 0\n",
    "    int_X = (X*255).clip(0,255).astype('uint8')\n",
    "    # N*784 -> N*28*28 -> 28*N*28 -> 28 * 28N\n",
    "    int_X_reshape = int_X.reshape(rows, -1,28,28).swapaxes(1,2).reshape(28*rows,-1)\n",
    "    display(Image.fromarray(int_X_reshape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updateProgress(msg):\n",
    "    sys.stdout.write('\\r')\n",
    "    sys.stdout.write(msg)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var, name):  \n",
    "    with tf.name_scope('summaries_'+str(name)):  \n",
    "        mean = tf.reduce_mean(var)  \n",
    "        tf.summary.scalar('mean', mean)  \n",
    "        stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))  \n",
    "        tf.summary.scalar('stddev', stddev)  \n",
    "        tf.summary.scalar('max', tf.reduce_max(var))  \n",
    "        tf.summary.scalar('min', tf.reduce_min(var))  \n",
    "        tf.summary.histogram('histogram', var)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Import MNIST Data'></a>\n",
    "## 1. Import MNIST Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 先把MNIST資料讀進來\n",
    "- Training Data: 訓練Model\n",
    "- Validataion Data: 訓練Model的時候, 同步監控目前模型的好壞\n",
    "- Testing Data: 訓練結束後, 評估模型的好壞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list裡的前面是picture X [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "後面是label Y [5 0 4 ..., 8 4 8]\n"
     ]
    }
   ],
   "source": [
    "with lzma.open(\"mnist.pkl.xz\", 'rb') as f:\n",
    "    train_set, validation_set, test_set = pickle.load(f, encoding='latin1')\n",
    "\n",
    "print('list裡的前面是picture X',train_set[0])\n",
    "print('後面是label Y',train_set[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size: 50000\n",
      "validataion data size: 10000\n",
      "testing data size: 10000\n",
      "picture shape: (784,)\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y = train_set\n",
    "validation_X, validation_y = validation_set\n",
    "test_X, test_y = test_set\n",
    "print('training data size:',len(train_X))\n",
    "print('validataion data size:',len(validation_X))\n",
    "print('testing data size:',len(test_X))\n",
    "print('picture shape:',train_X[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 把Y label變成one-hot representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_Y = np.eye(10)[train_y]\n",
    "test_Y = np.eye(10)[test_y]\n",
    "validation_Y = np.eye(10)[validation_y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='開始Deep Learning'></a>\n",
    "## 2. 開始Deep Nerual Network\n",
    "- What is DNN?  DNN就是很多層的f(WX+B)\n",
    "\n",
    "**這是一層的DNN(其實就是Softmax Regression)**：\n",
    "![](img/dnn_1.png)\n",
    "\n",
    "**這是很多層的DNN**\n",
    "![](img/dnn_2.png)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Deep Learning ABC \n",
    "    -  [A. 定義參數](#定義參數) \n",
    "    -  [B. 設計一個Model從X預測Y](#設計一個) \n",
    "    -  [C. 選一個loss function,](#選一個loss) \n",
    "    -  [D. 選一個optimizer](#選一個o) \n",
    "    -  [E. 開始執行訓練](#開始執行) \n",
    "    -  [F. 算一下正確率](#算一下正)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='定義參數'></a>\n",
    "### A. 定義參數(Placeholder, Variable, Constant)\n",
    "tips: 把要餵進Model的資料X,Y定義成placeholder, 把要讓電腦幫忙找的權重W,B定義成Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "lr = 0.01 # learning rate\n",
    "n_inputs = 784 # 每一行的维度\n",
    "n_classes = 10  # RNN最后的输出類別個数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "X =tf.placeholder(tf.float32, [None, n_inputs], name=\"X\")\n",
    "Y_ =tf.placeholder(tf.float32, [None, n_classes], name=\"Y_\")\n",
    "\n",
    "W = {\n",
    "    'wd1': tf.Variable(tf.random_normal([784,600], stddev=0.01), name=\"wd1\"),\n",
    "    'wd2': tf.Variable(tf.random_normal([600,480], stddev=0.01), name=\"wd2\"),\n",
    "    'out': tf.Variable(tf.random_normal([480, 10]), name=\"out\")\n",
    "}\n",
    "variable_summaries(W['wd1'],'wd1')\n",
    "variable_summaries(W['wd2'],'wd2')\n",
    "variable_summaries(W['out'],'out')\n",
    "\n",
    "B = {\n",
    "    'bd1': tf.Variable(tf.random_normal([600]),name=\"bd1\"),\n",
    "    'bd2': tf.Variable(tf.random_normal([480]), name=\"bd2\"),\n",
    "    'out': tf.Variable(tf.random_normal([10]), name=\"out\"),\n",
    "}\n",
    "\n",
    "variable_summaries(B['bd1'],'bd1')\n",
    "variable_summaries(B['bd2'],'bd2')\n",
    "variable_summaries(B['out'],'out')\n",
    "\n",
    "#tfdot() 不看!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='設計一個'></a>\n",
    "###  B. 設計一個Model從X & X history預測Y  \n",
    "Input Layer: X  \n",
    "Hidden Layer 1: $H_1=f_1(W_1X+B_1)$  \n",
    "Hidden Layer 2: $H_2=f_2(W_2H_1+B_2)$  \n",
    "Output Layer : $Y=f_3(W_3H_2+B_3)$  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1. Input Layer 輸入層\n",
    "- do nothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2. Hidden Layer 隱藏層 x 2\n",
    "- 線性(WX+B) + 非線性(activation function)  \n",
    "![](img/activation.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Hidden_Layer1\"):\n",
    "    _H1 = tf.matmul(X, W['wd1']) + B['bd1'] \n",
    "    H1 = tf.nn.relu(_H1, name=\"H1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Hidden_Layer2\"):\n",
    "    _H2 = tf.matmul(H1, W['wd2']) + B['bd2'] # (-1, 28) matmul (28, hidden_units) => (-1, hidden_units)\n",
    "    H2 = tf.nn.relu(_H2, name=\"H2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L3. Output Layer 輸出層\n",
    "- 第一步：線性 (重點：把output轉換成要分類的數量)\n",
    "- 第二步：非線性 (重點：把數值壓縮在0~1之間, 類似機率的表示方法)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('outlayer'):\n",
    "    _pred = tf.matmul(H2, W['out']) + B['out']\n",
    "    pred = tf.nn.softmax(_pred, name=\"pred\")\n",
    "    \n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(Y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='選一個loss'></a>\n",
    "###  C. 選一個loss function, 當作Machine learning的目標\n",
    "- cross_entorpy $-log(\\Pr(Y_{true}))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#這邊要注意, loss function裡面已經有做softmax, 所以logits記得帶沒有做softmax的\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=_pred, labels=Y_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='選一個o'></a>\n",
    "### D. 選一個optimizer, 根據Data和我們訂的目標找參數W, B\n",
    "- 試試看adaptive gradient descent(adagrad), 這個方法會在每個步驟都根據前面步驟的梯度來調整learing rate, 大致上的概念就是一開始走快一點, 接近最低點的時候走小步一點, 當梯度值突然很大的時候也走大步一點, 看一下李宏毅教授的上課影片就能理解    \n",
    "<br>\n",
    "$W^{t+1}=W^t- {\\frac{\\eta^t}{\\sigma^t}}g^t$  \n",
    "$\\sigma=\\sqrt{\\frac{1}{t+1}\\sum({g^i})^2}$\n",
    "<br>  \n",
    "$\\eta$: learning rate  \n",
    "$\\sigma$: 過去所有梯度的root mean square  \n",
    "$g$: 梯度值  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdagradOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='開始執行'></a>\n",
    "### E. 開始執行訓練(Training Data + Validataion Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "# Create a summary to monitor cost tensor\n",
    "with tf.name_scope('performance'):  \n",
    "    loss_scar = tf.summary.scalar('loss', loss)\n",
    "    # Create a summary to monitor accuracy tensor\n",
    "    acc_scar = tf.summary.scalar('accuracy', accuracy)\n",
    "    # Merge all summaries into a single op\n",
    "merged_summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#先創造一個session, 然後記得要init variable\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "LOG_DIR = 'tb-log5'\n",
    "if not os.path.exists(LOG_DIR):\n",
    "    os.mkdir(LOG_DIR)\n",
    "summary_writer_train = tf.summary.FileWriter(LOG_DIR+'/train',graph=tf.get_default_graph())\n",
    "summary_writer_validation = tf.summary.FileWriter(LOG_DIR+'/validation',graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, batch:300 loss:0.2885988652706146, acc:0.91469997167587282\n",
      "epoch:1, batch:300 loss:0.1726723611354828, acc:0.95139998197555548\n",
      "epoch:2, batch:300 loss:0.14686638116836548, acc:0.9577000141143799\n",
      "epoch:3, batch:300 loss:0.12102670967578888, acc:0.9663000106811523\n",
      "epoch:4, batch:300 loss:0.11033638566732407, acc:0.9685000181198123\n",
      "epoch:5, batch:300 loss:0.10239648073911667, acc:0.9697999954223633\n",
      "epoch:6, batch:300 loss:0.11012419313192368, acc:0.9679999947547913\n",
      "epoch:7, batch:300 loss:0.09443458914756775, acc:0.9726999998092651\n",
      "epoch:8, batch:300 loss:0.08842770755290985, acc:0.9745000004768372\n",
      "epoch:9, batch:300 loss:0.09069573134183884, acc:0.9732000231742859\n",
      "epoch:10, batch:300 loss:0.08624941110610962, acc:0.9754999876022339\n",
      "epoch:11, batch:300 loss:0.0873347669839859, acc:0.97479999065399178\n",
      "epoch:12, batch:300 loss:0.08525534719228745, acc:0.9740999937057495\n",
      "epoch:13, batch:300 loss:0.08181624114513397, acc:0.9764000177383423\n",
      "epoch:14, batch:300 loss:0.08127942681312561, acc:0.9764000177383423\n",
      "epoch:15, batch:300 loss:0.08126108348369598, acc:0.9757000207901001\n"
     ]
    }
   ],
   "source": [
    "epoch = 15\n",
    "batch_size = 128\n",
    "total_batch= len(train_X) / batch_size\n",
    "for ep in range(epoch+1):\n",
    "    for i in range(int(total_batch)+1):\n",
    "        rnd_idx = np.random.choice(train_X.shape[0], batch_size, replace=False)\n",
    "        batch_x = train_X[rnd_idx]\n",
    "        batch_y = train_Y[rnd_idx]\n",
    "        _, loss_s, acc_s, summary= sess.run([optimizer, loss_scar, acc_scar, merged_summary_op], feed_dict={X: batch_x, Y_:batch_y})\n",
    "        summary_writer_train.add_summary(summary, ep * total_batch + i)\n",
    "        if i%100 ==0:\n",
    "            loss_s, acc_s, summary= sess.run([loss_scar, acc_scar, merged_summary_op], feed_dict={X: validation_X , Y_: validation_Y})\n",
    "            acc = accuracy.eval({X: validation_X , Y_: validation_Y})\n",
    "            los=loss.eval({X: validation_X , Y_: validation_Y})\n",
    "            summary_writer_validation.add_summary(summary, ep * total_batch + i)\n",
    "            updateProgress('epoch:{x0}, batch:{x4} loss:{x3}, acc:{x2}'.format(x0=ep,x1=i,x2=acc,x3=los,x4=i))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 抓出前五筆訓練資料的預測結果 Y_softmax (注意：這個是one-hot的格式)\n",
    "pred_tmp = pred.eval(feed_dict={X: train_X[21:30]})\n",
    "pred_tmp_df = pd.DataFrame(pred_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict:  [0 9 1 1 2 4 3 2 7]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAAcCAAAAABghI05AAAGXElEQVR4nO1YbWxUVRp+oKWQFiio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\nj8Iv/+ddXsOvBT8AJ0+kL8nqYuIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=252x28 at 0x10EE9C160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  [0 9 1 1 2 4 3 2 7]\n",
      "第21~30筆資料的比對結果:       0\n",
      "0  True\n",
      "1  True\n",
      "2  True\n",
      "3  True\n",
      "4  True\n",
      "5  True\n",
      "6  True\n",
      "7  True\n",
      "8  True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "_ = pred_tmp_df.apply(np.argmax,axis=1)\n",
    "print('predict: ',_.values)\n",
    "showX(train_X[21:30])\n",
    "print('answer: ',train_y[21:30])\n",
    "\n",
    "_ = correct_pred.eval({X: train_X[21:30] , Y_: train_Y[21:30]})\n",
    "print('第21~30筆資料的比對結果:',pd.DataFrame(_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='算一下正'></a>\n",
    "### F. 算一下正確率Accuracy (用Testing Data)\n",
    "- unseen data\n",
    "- generalize from the training set to the test set\n",
    "- 泛化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9752\n"
     ]
    }
   ],
   "source": [
    "#pred_test = pred.eval(feed_dict={X: test_X})\n",
    "#pred_test_df = pd.DataFrame(pred_test)\n",
    "#pred_test_df = pred_test_df.apply(np.argmax,axis=1)\n",
    "# predict all X and get the accuracy\n",
    "acc = sess.run(accuracy, feed_dict={X: test_X , Y_: test_Y})\n",
    "print('Accuracy:',acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#把圖片的label存到metadata.tsv\n",
    "metadata_file_path = os.path.join(LOG_DIR, 'metadata.tsv')\n",
    "with open(metadata_file_path, 'w') as metadata_file:\n",
    "    for row in range(len(test_y)):\n",
    "        c=test_y[row]\n",
    "        metadata_file.write('{}\\n'.format(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save variable\n",
    "Input_Var = tf.Variable(test_X, name='Input_var')\n",
    "H1_Var = tf.Variable(H1.eval({X: test_X}), name='H1_var')\n",
    "H2_Var = tf.Variable(H2.eval({X: test_X}), name='H2_var')\n",
    "Out_Var = tf.Variable(pred.eval({X: test_X}), name='Out_var')\n",
    "\n",
    "saver = tf.train.Saver([Input_Var,H1_Var,H2_Var,Out_Var])\n",
    "sess.run(Input_Var.initializer)\n",
    "sess.run(H1_Var.initializer)\n",
    "sess.run(H2_Var.initializer)\n",
    "sess.run(Out_Var.initializer)\n",
    "saver.save(sess, os.path.join(LOG_DIR, 'test_images.ckpt'))\n",
    "\n",
    "#在config裡面用一個embedding關聯 tensor & its metadata\n",
    "config = projector.ProjectorConfig()\n",
    "# One can add multiple embeddings.\n",
    "\n",
    "embedding1 = config.embeddings.add()\n",
    "embedding1.tensor_name = Input_Var.name\n",
    "embedding1.metadata_path = metadata_file_path\n",
    "\n",
    "embedding2 = config.embeddings.add()\n",
    "embedding2.tensor_name = H1_Var.name\n",
    "embedding2.metadata_path = metadata_file_path\n",
    "\n",
    "embedding3 = config.embeddings.add()\n",
    "embedding3.tensor_name = H2_Var.name\n",
    "embedding3.metadata_path = metadata_file_path\n",
    "\n",
    "embedding4 = config.embeddings.add()\n",
    "embedding4.tensor_name = Out_Var.name\n",
    "embedding4.metadata_path = metadata_file_path\n",
    "\n",
    "#embedding.sprite.image_path = os.path.join(LOG_DIR, 'img/mnist_10k_sprite.png')\n",
    "# Specify the width and height of a single thumbnail.\n",
    "#embedding.sprite.single_image_dim.extend([28, 28])\n",
    "\n",
    "\n",
    "\n",
    "# Saves a config file that TensorBoard will read during startup.\n",
    "projector.visualize_embeddings(tf.summary.FileWriter(LOG_DIR), config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/mnist001.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!tensorboard --logdir=tb-log1 --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework \n",
    "- 玩玩看CIFAR 10 Data set\n",
    "- 李宏毅教授上課影片   \n",
    "[Regression](https://www.youtube.com/watch?v=fegAeph9UaA) : ML 101  \n",
    "[Where does the error come from](https://www.youtube.com/watch?v=D_S6y0Jm6dQ) : Bias, Variance     \n",
    "[Gradient Descent](https://www.youtube.com/watch?v=yKKNr-QKz2Q) : some useful tips   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='reference'></a>\n",
    "## Reference\n",
    "- https://my.oschina.net/yilian/blog/664077"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 補充資料\n",
    "![](img/dmap.jpeg)\n",
    "\n",
    "![](img/one_hot.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_model=True\n",
    "restore_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save dnn model done /tmp/dnn_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "if save_model:\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, \"/tmp/dnn_model.ckpt\")\n",
    "    print('save dnn model done',save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/dnn_model.ckpt\n",
      "restore dnn model done\n"
     ]
    }
   ],
   "source": [
    "if restore_model:\n",
    "    sess=tf.Session()\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, \"/tmp/dnn_model.ckpt\")\n",
    "    print('restore dnn model done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
