{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST 手寫數字辨識 (MNIST_CNN_TF)\n",
    "\n",
    "2017/06/26  \n",
    "徐仕杰 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips:\n",
    "- 記得要download data set: \n",
    "[Mnist](https://github.com/Backlu/tf-keras-tutorial/blob/master/basic/mnist.pkl.xz)\n",
    "- 在command前面加** ! **可以執行console command\n",
    "- 在command前面加** ? **可以查詢Help\n",
    "- 什麼是one-hot representation:\n",
    "[one-hot](https://www.quora.com/What-is-one-hot-encoding-and-when-is-it-used-in-data-science)  \n",
    "- 好用的markdown語法\n",
    "[markdown](https://www.zybuluo.com/codeep/note/163962#1如何输入一个方程式序列)  \n",
    "<br>\n",
    "- import PIL error : pip install Pillow\n",
    "- import pandas error: pip install pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "-  [Import Package & Functions](#import) \n",
    "-  [1. Import MNIST Data](#Import Data) \n",
    "-  [2. 開始Deep Learning - CNN](#開始Deep Learning)  \n",
    "  -  [A. 定義參數](#定義參數) \n",
    "  -  [B. 設計一個Model從X預測Y](#設計一個) \n",
    "  -  [C. 選一個loss function,](#選一個loss) \n",
    "  -  [D. 選一個optimizer](#選一個o) \n",
    "  -  [E. 開始執行訓練](#開始執行) \n",
    "  -  [F. 算一下正確率](#算一下正)  \n",
    "<br>\n",
    "-  [3. Reference](#reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='import'></a>\n",
    "## Import Package & Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import lzma\n",
    "import pickle\n",
    "from IPython.display import display\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def showX(X):\n",
    "    int_X = (X*255).clip(0,255).astype('uint8')\n",
    "    # N*784 -> N*28*28 -> 28*N*28 -> 28 * 28N\n",
    "    int_X_reshape = int_X.reshape(-1,28,28).swapaxes(0,1).reshape(28,-1)\n",
    "    display(Image.fromarray(int_X_reshape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updateProgress(msg):\n",
    "    sys.stdout.write('\\r')\n",
    "    sys.stdout.write(msg)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var, name):  \n",
    "    with tf.name_scope('summaries_'+str(name)):  \n",
    "        mean = tf.reduce_mean(var)  \n",
    "        tf.summary.scalar('mean', mean)  \n",
    "        stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))  \n",
    "        tf.summary.scalar('stddev', stddev)  \n",
    "        tf.summary.scalar('max', tf.reduce_max(var))  \n",
    "        tf.summary.scalar('min', tf.reduce_min(var))  \n",
    "        tf.summary.histogram('histogram', var)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Import MNIST Data'></a>\n",
    "## 1. Import MNIST Data\n",
    "#### 先把MNIST資料讀進來\n",
    "- Training Data: 訓練Model\n",
    "- Validataion Data: 訓練Model的時候, 同步監控目前模型的好壞\n",
    "- Testing Data: 訓練結束後, 評估模型的好壞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list裡的前面是picture X [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "後面是label Y [5 0 4 ..., 8 4 8]\n"
     ]
    }
   ],
   "source": [
    "with lzma.open(\"mnist.pkl.xz\", 'rb') as f:\n",
    "    train_set, validation_set, test_set = pickle.load(f, encoding='latin1')\n",
    "    \n",
    "print('list裡的前面是picture X',train_set[0])\n",
    "print('後面是label Y',train_set[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size: 50000\n",
      "validataion data size: 10000\n",
      "testing data size: 10000\n",
      "picture shape: (784,)\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y = train_set\n",
    "validation_X, validation_y = validation_set\n",
    "test_X, test_y = test_set\n",
    "print('training data size:',len(train_X))\n",
    "print('validataion data size:',len(validation_X))\n",
    "print('testing data size:',len(test_X))\n",
    "print('picture shape:',train_X[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 把Y label變成one-hot representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y = np.eye(10)[train_y]\n",
    "test_Y = np.eye(10)[test_y]\n",
    "validation_Y = np.eye(10)[validation_y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='開始Deep Learning'></a>\n",
    "## 2. 開始Deep Learning - CNN\n",
    "- What is CNN?  \n",
    "![](img/cnn_1.gif)\n",
    "![](img/cnn_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Deep Learning ABC \n",
    "    -  [A. 定義參數](#定義參數) \n",
    "    -  [B. 設計一個Model從X預測Y](#設計一個) \n",
    "    -  [C. 選一個loss function,](#選一個loss) \n",
    "    -  [D. 選一個optimizer](#選一個o) \n",
    "    -  [E. 開始執行訓練](#開始執行) \n",
    "    -  [F. 算一下正確率](#算一下正)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='定義參數'></a>\n",
    "### A. 定義參數(Placeholder, Variable, Constant)\n",
    "tips: 把要餵進Model的資料X,Y定義成placeholder, 把要讓電腦幫忙找的權重W,B定義成Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, shape=[None, 784], name=\"X\")\n",
    "Y_ = tf.placeholder(tf.float32, shape=[None, 10], name=\"Y_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 設定 weight 和 bais\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape=shape, stddev=0.1)\n",
    "    W = tf.Variable(initial, name ='W')\n",
    "    variable_summaries(W,'W')\n",
    "    return W\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(value=0.1, shape=shape)\n",
    "    B = tf.Variable(initial, name = 'b')\n",
    "    variable_summaries(B,'B')\n",
    "    return B\n",
    "# 設定 cnn 的 layers\n",
    "def conv2d(X, W):\n",
    "    return tf.nn.conv2d(X, W, strides=[1,1,1,1], padding='SAME',use_cudnn_on_gpu=True)\n",
    "    #stride:每次移動步伐, padding:在圖片的四周補0, SAME就是補到conv後要和原圖一樣大張\n",
    "def max_pool_2x2(X):\n",
    "    return tf.nn.max_pool(X, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    #ksize:框框大小, stride:每次移動步伐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='設計一個'></a>\n",
    "###  B. 設計一個Model從X & X history預測Y  \n",
    "Input Layer: X  \n",
    "Hidden Layer 1: $H_1=pooling(f(W_1(X)+B_1)$  \n",
    "Hidden Layer 2: $H_2=pooling(f_2(W_2H_1+B_2))$  \n",
    "Output Layer : $Y=pooling(f_3(W_3H_2+B_3))$  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1. Input Layer 輸入層\n",
    "- do nothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2. Hidden Layer 隱藏層 x 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fisrt layer\n",
    "with tf.name_scope('conv1'):\n",
    "    ## variables\n",
    "    W_conv1 = weight_variable([3,3,1,32]) # filter_height, filter_width, in_channels, out_channels\n",
    "    b_conv1 = bias_variable([32])\n",
    "    ## build the layer\n",
    "    X_image = tf.reshape(X, [-1, 28, 28,1]) # batch, in_height, in_width, in_channels\n",
    "    h_conv1 = tf.nn.relu(conv2d(X_image, W_conv1) + b_conv1)\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# second layer\n",
    "with tf.name_scope('conv2'):\n",
    "    ## variables\n",
    "    W_conv2 = weight_variable([3,3,32,64])\n",
    "    b_conv2 = bias_variable([64])\n",
    "    ## build the layer\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "    h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fully-connected layer\n",
    "with tf.name_scope('full'):\n",
    "    W_fc1 = weight_variable([7*7*64, 1024])\n",
    "    b_fc1 = bias_variable([1024])\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1)+b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L3. Output Layer 輸出層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('dropout'):\n",
    "    keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# Readout\n",
    "with tf.name_scope('output'):\n",
    "    W_fc2 = weight_variable([1024,10])\n",
    "    b_fc2 = bias_variable([10])\n",
    "    _pred = tf.matmul(h_fc1_drop, W_fc2)+b_fc2\n",
    "    pred = tf.nn.softmax(_pred, name=\"pred\")\n",
    "\n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(Y_, 1), name=\"correction\")\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='選一個loss'></a>\n",
    "###  C. 選一個loss function, 當作Machine learning的目標\n",
    "- cross_entorpy $-log(\\Pr(Y_{true}))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss =  tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y_, logits=_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='選一個o'></a>\n",
    "### D. 選一個optimizer, 根據Data和我們訂的目標找參數W, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(1e-4).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='開始執行'></a>\n",
    "### E. 開始執行訓練(Training Data + Validataion Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "# Create a summary to monitor cost tensor\n",
    "with tf.name_scope('performance'):  \n",
    "    loss_scar = tf.summary.scalar('loss', loss)\n",
    "    # Create a summary to monitor accuracy tensor\n",
    "    acc_scar = tf.summary.scalar('accuracy', accuracy)\n",
    "    # Merge all summaries into a single op\n",
    "merged_summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "\n",
    "if not os.path.exists('tb-log_6'):\n",
    "    os.mkdir('tb-log_6')\n",
    "summary_writer_train = tf.summary.FileWriter('tb-log1/train',graph=tf.get_default_graph())\n",
    "summary_writer_validation = tf.summary.FileWriter('tb-log1/validation',graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, batch:300 loss:0.2337394803762436, acc:0.9363999962806702\n",
      "epoch:1, batch:300 loss:0.14073903858661652, acc:0.9609000086784363\n",
      "epoch:2, batch:300 loss:0.10170849412679672, acc:0.9725999832153322\n",
      "epoch:3, batch:300 loss:0.08144901692867279, acc:0.9781000018119812\n",
      "epoch:4, batch:300 loss:0.07447440922260284, acc:0.9778000116348267\n",
      "epoch:5, batch:300 loss:0.06347649544477463, acc:0.9812999963760376\n",
      "epoch:6, batch:300 loss:0.057572826743125916, acc:0.9825999736785889\n",
      "epoch:7, batch:300 loss:0.05346352607011795, acc:0.9839000105857849\n",
      "epoch:8, batch:300 loss:0.051120053976774216, acc:0.9854000210762024\n",
      "epoch:9, batch:300 loss:0.04835669323801994, acc:0.98680001497268682\n",
      "epoch:10, batch:300 loss:0.047548405826091766, acc:0.9858000278472906\n",
      "epoch:11, batch:300 loss:0.045138753950595856, acc:0.9878000020980835\n",
      "epoch:12, batch:300 loss:0.04188016802072525, acc:0.9873999953269958\n",
      "epoch:13, batch:300 loss:0.04293319210410118, acc:0.9876999855041504\n",
      "epoch:14, batch:300 loss:0.03902275860309601, acc:0.9883000254631042\n",
      "epoch:15, batch:300 loss:0.03881342336535454, acc:0.9890999794006348\n"
     ]
    }
   ],
   "source": [
    "#%%timeit -r 1 -n 1\n",
    "epoch = 15\n",
    "batch_size = 128\n",
    "total_batch= len(train_X) / batch_size\n",
    "for ep in range(epoch+1):\n",
    "    for i in range(int(total_batch)+1):\n",
    "        rnd_idx = np.random.choice(train_X.shape[0], batch_size, replace=False)\n",
    "        batch_x = train_X[rnd_idx]\n",
    "        batch_y = train_Y[rnd_idx]\n",
    "        _, loss_s, acc_s, summary= sess.run([optimizer, loss_scar, acc_scar, merged_summary_op], feed_dict={X: batch_x, Y_:batch_y, keep_prob:0.5})\n",
    "        summary_writer_train.add_summary(summary, ep * total_batch + i)\n",
    "        if i%100 ==0:\n",
    "            loss_v, acc_v, loss_s, acc_s, summary= sess.run([loss, accuracy, loss_scar, acc_scar, merged_summary_op], feed_dict={X: validation_X , Y_: validation_Y, keep_prob:1.0 })\n",
    "            #acc = accuracy.eval({X: validation_X , Y_: validation_Y, keep_prob:1.0})\n",
    "            #los=loss.eval({X: validation_X , Y_: validation_Y, keep_prob:1.0})\n",
    "            summary_writer_validation.add_summary(summary, ep * total_batch + i)\n",
    "            updateProgress('epoch:{x0}, batch:{x4} loss:{x3}, acc:{x2}'.format(x0=ep,x1=i,x2=acc_v,x3=loss_v,x4=i))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.999964e-01</td>\n",
       "      <td>2.742643e-07</td>\n",
       "      <td>7.360870e-07</td>\n",
       "      <td>8.114490e-07</td>\n",
       "      <td>8.838399e-08</td>\n",
       "      <td>2.574987e-08</td>\n",
       "      <td>1.394657e-06</td>\n",
       "      <td>1.112339e-07</td>\n",
       "      <td>6.730507e-08</td>\n",
       "      <td>5.774911e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.964998e-06</td>\n",
       "      <td>6.118173e-06</td>\n",
       "      <td>9.628698e-06</td>\n",
       "      <td>5.122107e-05</td>\n",
       "      <td>2.426854e-03</td>\n",
       "      <td>7.342273e-07</td>\n",
       "      <td>7.255342e-07</td>\n",
       "      <td>4.102618e-04</td>\n",
       "      <td>5.981723e-04</td>\n",
       "      <td>9.964934e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.374750e-08</td>\n",
       "      <td>9.999796e-01</td>\n",
       "      <td>5.742968e-07</td>\n",
       "      <td>4.098836e-10</td>\n",
       "      <td>7.018789e-06</td>\n",
       "      <td>1.599629e-10</td>\n",
       "      <td>2.047665e-08</td>\n",
       "      <td>1.204938e-05</td>\n",
       "      <td>6.715453e-07</td>\n",
       "      <td>1.519913e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.026599e-06</td>\n",
       "      <td>9.899493e-01</td>\n",
       "      <td>8.863462e-03</td>\n",
       "      <td>7.703724e-04</td>\n",
       "      <td>3.456290e-04</td>\n",
       "      <td>4.839696e-05</td>\n",
       "      <td>9.610063e-07</td>\n",
       "      <td>1.527787e-05</td>\n",
       "      <td>9.612859e-07</td>\n",
       "      <td>2.542442e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.228101e-09</td>\n",
       "      <td>4.035215e-07</td>\n",
       "      <td>9.997242e-01</td>\n",
       "      <td>7.274361e-05</td>\n",
       "      <td>1.716300e-12</td>\n",
       "      <td>4.576439e-10</td>\n",
       "      <td>3.849399e-10</td>\n",
       "      <td>2.070270e-07</td>\n",
       "      <td>2.023485e-04</td>\n",
       "      <td>6.689154e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.071156e-09</td>\n",
       "      <td>3.079203e-06</td>\n",
       "      <td>2.409394e-08</td>\n",
       "      <td>7.530954e-08</td>\n",
       "      <td>9.999465e-01</td>\n",
       "      <td>6.675870e-07</td>\n",
       "      <td>3.900594e-09</td>\n",
       "      <td>2.306442e-05</td>\n",
       "      <td>1.803648e-06</td>\n",
       "      <td>2.477383e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.047165e-13</td>\n",
       "      <td>2.118370e-10</td>\n",
       "      <td>4.143708e-10</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>9.095837e-15</td>\n",
       "      <td>3.555252e-09</td>\n",
       "      <td>7.072231e-16</td>\n",
       "      <td>5.365857e-10</td>\n",
       "      <td>8.070611e-09</td>\n",
       "      <td>2.335889e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.075092e-08</td>\n",
       "      <td>4.982663e-08</td>\n",
       "      <td>9.997979e-01</td>\n",
       "      <td>2.309730e-07</td>\n",
       "      <td>1.426552e-12</td>\n",
       "      <td>1.205247e-09</td>\n",
       "      <td>1.234470e-11</td>\n",
       "      <td>1.563299e-04</td>\n",
       "      <td>4.538136e-05</td>\n",
       "      <td>5.986393e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.603812e-05</td>\n",
       "      <td>4.291572e-04</td>\n",
       "      <td>5.779758e-03</td>\n",
       "      <td>1.385457e-04</td>\n",
       "      <td>1.067681e-04</td>\n",
       "      <td>1.119595e-05</td>\n",
       "      <td>3.199254e-07</td>\n",
       "      <td>9.892409e-01</td>\n",
       "      <td>8.945113e-04</td>\n",
       "      <td>3.372800e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0             1             2             3             4  \\\n",
       "0  9.999964e-01  2.742643e-07  7.360870e-07  8.114490e-07  8.838399e-08   \n",
       "1  2.964998e-06  6.118173e-06  9.628698e-06  5.122107e-05  2.426854e-03   \n",
       "2  1.374750e-08  9.999796e-01  5.742968e-07  4.098836e-10  7.018789e-06   \n",
       "3  3.026599e-06  9.899493e-01  8.863462e-03  7.703724e-04  3.456290e-04   \n",
       "4  3.228101e-09  4.035215e-07  9.997242e-01  7.274361e-05  1.716300e-12   \n",
       "5  3.071156e-09  3.079203e-06  2.409394e-08  7.530954e-08  9.999465e-01   \n",
       "6  1.047165e-13  2.118370e-10  4.143708e-10  9.999998e-01  9.095837e-15   \n",
       "7  6.075092e-08  4.982663e-08  9.997979e-01  2.309730e-07  1.426552e-12   \n",
       "8  2.603812e-05  4.291572e-04  5.779758e-03  1.385457e-04  1.067681e-04   \n",
       "\n",
       "              5             6             7             8             9  \n",
       "0  2.574987e-08  1.394657e-06  1.112339e-07  6.730507e-08  5.774911e-08  \n",
       "1  7.342273e-07  7.255342e-07  4.102618e-04  5.981723e-04  9.964934e-01  \n",
       "2  1.599629e-10  2.047665e-08  1.204938e-05  6.715453e-07  1.519913e-09  \n",
       "3  4.839696e-05  9.610063e-07  1.527787e-05  9.612859e-07  2.542442e-06  \n",
       "4  4.576439e-10  3.849399e-10  2.070270e-07  2.023485e-04  6.689154e-10  \n",
       "5  6.675870e-07  3.900594e-09  2.306442e-05  1.803648e-06  2.477383e-05  \n",
       "6  3.555252e-09  7.072231e-16  5.365857e-10  8.070611e-09  2.335889e-07  \n",
       "7  1.205247e-09  1.234470e-11  1.563299e-04  4.538136e-05  5.986393e-09  \n",
       "8  1.119595e-05  3.199254e-07  9.892409e-01  8.945113e-04  3.372800e-03  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 抓出前五筆訓練資料的預測結果 Y_softmax (注意：這個是one-hot的格式)\n",
    "pred_tmp = pred.eval(feed_dict={X: train_X[21:30], keep_prob:1.0})\n",
    "pred_tmp_df = pd.DataFrame(pred_tmp)\n",
    "pred_tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict:  [0 9 1 1 2 4 3 2 7]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAAcCAAAAABghI05AAAGXElEQVR4nO1YbWxUVRp+oKWQFiio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\nj8Iv/+ddXsOvBT8AJ0+kL8nqYuIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=252x28 at 0x12C4189E8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  [0 9 1 1 2 4 3 2 7]\n",
      "第21~30筆資料的比對結果:    0\n",
      "0  0\n",
      "1  9\n",
      "2  1\n",
      "3  1\n",
      "4  2\n",
      "5  4\n",
      "6  3\n",
      "7  2\n",
      "8  7\n",
      "第21~30筆資料的比對結果:       0\n",
      "0  True\n",
      "1  True\n",
      "2  True\n",
      "3  True\n",
      "4  True\n",
      "5  True\n",
      "6  True\n",
      "7  True\n",
      "8  True\n"
     ]
    }
   ],
   "source": [
    "_ = pred_tmp_df.apply(np.argmax,axis=1)\n",
    "print('predict: ',_.values)\n",
    "showX(train_X[21:30])\n",
    "print('answer: ',train_y[21:30])\n",
    "\n",
    "print('第21~30筆資料的比對結果:',pd.DataFrame(_))\n",
    "\n",
    "_ = correct_pred.eval({X: train_X[21:30] , Y_: train_Y[21:30], keep_prob:1.0})\n",
    "print('第21~30筆資料的比對結果:',pd.DataFrame(_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='算一下正'></a>\n",
    "### F. 算一下正確率Accuracy (用Testing Data)\n",
    "- unseen data\n",
    "- generalize from the training set to the test set\n",
    "- 泛化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9903\n"
     ]
    }
   ],
   "source": [
    "# predict all X and get the accuracy\n",
    "_ = accuracy.eval({X: test_X , Y_: test_Y, keep_prob:1.0})\n",
    "print('Accuracy:',_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
