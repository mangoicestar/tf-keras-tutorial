{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST 手寫數字辨識 (MNIST_CNN_TF)\n",
    "\n",
    "2017/06/26  \n",
    "徐仕杰 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips:\n",
    "- 記得要download data set: \n",
    "[Mnist](https://github.com/Backlu/tf-keras-tutorial/blob/master/basic/mnist.pkl.xz)\n",
    "- 在command前面加** ! **可以執行console command\n",
    "- 在command前面加** ? **可以查詢Help\n",
    "- 什麼是one-hot representation:\n",
    "[one-hot](https://www.quora.com/What-is-one-hot-encoding-and-when-is-it-used-in-data-science)  \n",
    "- 好用的markdown語法\n",
    "[markdown](https://www.zybuluo.com/codeep/note/163962#1如何输入一个方程式序列)  \n",
    "<br>\n",
    "- import PIL error : pip install Pillow\n",
    "- import pandas error: pip install pandas\n",
    "- import lzma error: 請用python 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "-  [Import Package & Functions](#import) \n",
    "-  [1. Import MNIST Data](#Import Data) \n",
    "-  [2. 開始Deep Learning - CNN](#開始Deep Learning)  \n",
    "  -  [A. 定義參數](#定義參數) \n",
    "  -  [B. 設計一個Model從X預測Y](#設計一個) \n",
    "  -  [C. 選一個loss function,](#選一個loss) \n",
    "  -  [D. 選一個optimizer](#選一個o) \n",
    "  -  [E. 開始執行訓練](#開始執行) \n",
    "  -  [F. 算一下正確率](#算一下正)  \n",
    "<br>\n",
    "-  [3. Reference](#reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='import'></a>\n",
    "## Import Package & Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import lzma\n",
    "import pickle\n",
    "from IPython.display import display\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def showX(X):\n",
    "    int_X = (X*255).clip(0,255).astype('uint8')\n",
    "    # N*784 -> N*28*28 -> 28*N*28 -> 28 * 28N\n",
    "    int_X_reshape = int_X.reshape(-1,28,28).swapaxes(0,1).reshape(28,-1)\n",
    "    display(Image.fromarray(int_X_reshape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updateProgress(msg):\n",
    "    sys.stdout.write('\\r')\n",
    "    sys.stdout.write(msg)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var, name):  \n",
    "    with tf.name_scope('summaries_'+str(name)):  \n",
    "        mean = tf.reduce_mean(var)  \n",
    "        tf.summary.scalar('mean', mean)  \n",
    "        stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))  \n",
    "        tf.summary.scalar('stddev', stddev)  \n",
    "        tf.summary.scalar('max', tf.reduce_max(var))  \n",
    "        tf.summary.scalar('min', tf.reduce_min(var))  \n",
    "        tf.summary.histogram('histogram', var)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Import MNIST Data'></a>\n",
    "## 1. Import MNIST Data\n",
    "#### 先把MNIST資料讀進來\n",
    "- Training Data: 訓練Model\n",
    "- Validataion Data: 訓練Model的時候, 同步監控目前模型的好壞\n",
    "- Testing Data: 訓練結束後, 評估模型的好壞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list裡的前面是picture X [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "後面是label Y [5 0 4 ..., 8 4 8]\n"
     ]
    }
   ],
   "source": [
    "with lzma.open(\"mnist.pkl.xz\", 'rb') as f:\n",
    "    train_set, validation_set, test_set = pickle.load(f, encoding='latin1')\n",
    "    \n",
    "print('list裡的前面是picture X',train_set[0])\n",
    "print('後面是label Y',train_set[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size: 50000\n",
      "validataion data size: 10000\n",
      "testing data size: 10000\n",
      "picture shape: (784,)\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y = train_set\n",
    "validation_X, validation_y = validation_set\n",
    "test_X, test_y = test_set\n",
    "print('training data size:',len(train_X))\n",
    "print('validataion data size:',len(validation_X))\n",
    "print('testing data size:',len(test_X))\n",
    "print('picture shape:',train_X[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 把Y label變成one-hot representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_Y = np.eye(10)[train_y]\n",
    "test_Y = np.eye(10)[test_y]\n",
    "validation_Y = np.eye(10)[validation_y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='開始Deep Learning'></a>\n",
    "## 2. 開始Deep Learning - CNN\n",
    "- What is CNN?  \n",
    "![](img/cnn_1.gif)\n",
    "![](img/cnn_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Deep Learning ABC \n",
    "    -  [A. 定義參數](#定義參數) \n",
    "    -  [B. 設計一個Model從X預測Y](#設計一個) \n",
    "    -  [C. 選一個loss function,](#選一個loss) \n",
    "    -  [D. 選一個optimizer](#選一個o) \n",
    "    -  [E. 開始執行訓練](#開始執行) \n",
    "    -  [F. 算一下正確率](#算一下正)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='定義參數'></a>\n",
    "### A. 定義參數(Placeholder, Variable, Constant)\n",
    "tips: 把要餵進Model的資料X,Y定義成placeholder, 把要讓電腦幫忙找的權重W,B定義成Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, shape=[None, 784], name=\"X\")\n",
    "Y_ = tf.placeholder(tf.float32, shape=[None, 10], name=\"Y_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 設定 weight 和 bais\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape=shape, stddev=0.1)\n",
    "    W = tf.Variable(initial, name ='W')\n",
    "    variable_summaries(W,'W')\n",
    "    return W\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(value=0.1, shape=shape)\n",
    "    B = tf.Variable(initial, name = 'b')\n",
    "    variable_summaries(B,'B')\n",
    "    return B\n",
    "# 設定 cnn 的 layers\n",
    "def conv2d(X, W):\n",
    "    return tf.nn.conv2d(X, W, strides=[1,1,1,1], padding='SAME',use_cudnn_on_gpu=True)\n",
    "    #stride:每次移動步伐, padding:在圖片的四周補0, SAME就是補到conv後要和原圖一樣大張\n",
    "def max_pool_2x2(X):\n",
    "    return tf.nn.max_pool(X, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    #ksize:框框大小, stride:每次移動步伐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='設計一個'></a>\n",
    "###  B. 設計一個Model從X & X history預測Y  \n",
    "Input Layer: X  \n",
    "Hidden Layer 1: $H_1=pooling(f(W_1(X)+B_1)$  \n",
    "Hidden Layer 2: $H_2=pooling(f_2(W_2H_1+B_2))$  \n",
    "Output Layer : $Y=pooling(f_3(W_3H_2+B_3))$  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1. Input Layer 輸入層\n",
    "- do nothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2. Hidden Layer 隱藏層 x 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fisrt layer\n",
    "with tf.name_scope('conv1'):\n",
    "    ## variables\n",
    "    W_conv1 = weight_variable([3,3,1,32]) # filter_height, filter_width, in_channels, out_channels\n",
    "    b_conv1 = bias_variable([32])\n",
    "    ## build the layer\n",
    "    X_image = tf.reshape(X, [-1, 28, 28,1]) # batch, in_height, in_width, in_channels\n",
    "    h_conv1 = tf.nn.relu(conv2d(X_image, W_conv1) + b_conv1)\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# second layer\n",
    "with tf.name_scope('conv2'):\n",
    "    ## variables\n",
    "    W_conv2 = weight_variable([3,3,32,64])\n",
    "    b_conv2 = bias_variable([64])\n",
    "    ## build the layer\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "    h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fully-connected layer\n",
    "with tf.name_scope('full'):\n",
    "    W_fc1 = weight_variable([7*7*64, 1024])\n",
    "    b_fc1 = bias_variable([1024])\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1)+b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L3. Output Layer 輸出層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('dropout'):\n",
    "    keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# Readout\n",
    "with tf.name_scope('output'):\n",
    "    W_fc2 = weight_variable([1024,10])\n",
    "    b_fc2 = bias_variable([10])\n",
    "    _pred = tf.matmul(h_fc1_drop, W_fc2)+b_fc2\n",
    "    pred = tf.nn.softmax(_pred, name=\"pred\")\n",
    "\n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(Y_, 1), name=\"correction\")\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='選一個loss'></a>\n",
    "###  C. 選一個loss function, 當作Machine learning的目標\n",
    "- cross_entorpy $-log(\\Pr(Y_{true}))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss =  tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y_, logits=_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='選一個o'></a>\n",
    "### D. 選一個optimizer, 根據Data和我們訂的目標找參數W, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(1e-4).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='開始執行'></a>\n",
    "### E. 開始執行訓練(Training Data + Validataion Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "# Create a summary to monitor cost tensor\n",
    "with tf.name_scope('performance'):  \n",
    "    loss_scar = tf.summary.scalar('loss', loss)\n",
    "    # Create a summary to monitor accuracy tensor\n",
    "    acc_scar = tf.summary.scalar('accuracy', accuracy)\n",
    "    # Merge all summaries into a single op\n",
    "merged_summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "\n",
    "if not os.path.exists('tb-log_6'):\n",
    "    os.mkdir('tb-log_6')\n",
    "summary_writer_train = tf.summary.FileWriter('tb-log1/train',graph=tf.get_default_graph())\n",
    "summary_writer_validation = tf.summary.FileWriter('tb-log1/validation',graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, batch:300 loss:0.2522891163825989, acc:0.93190008401870731\n",
      "epoch:1, batch:300 loss:0.15260650217533112, acc:0.9574002027511597\n",
      "epoch:2, batch:300 loss:0.11232933402061462, acc:0.9688001275062561\n",
      "epoch:3, batch:300 loss:0.08874470740556717, acc:0.9756001234054565\n",
      "epoch:4, batch:300 loss:0.0763041079044342, acc:0.97780013084411625\n",
      "epoch:5, batch:300 loss:0.06734831631183624, acc:0.9805001020431519\n",
      "epoch:6, batch:300 loss:0.06283014267683029, acc:0.9819001555442813\n",
      "epoch:7, batch:300 loss:0.058500535786151886, acc:0.9830001592636108\n",
      "epoch:8, batch:300 loss:0.0523262657225132, acc:0.984800159931182954\n",
      "epoch:9, batch:300 loss:0.04945176839828491, acc:0.98590016365051272\n",
      "epoch:10, batch:300 loss:0.046321868896484375, acc:0.9863001108169556\n",
      "epoch:11, batch:300 loss:0.045690495520830154, acc:0.9862001538276672\n",
      "epoch:12, batch:300 loss:0.041703756898641586, acc:0.987800121307373\n",
      "epoch:13, batch:300 loss:0.04176029562950134, acc:0.98740011453628543\n",
      "epoch:14, batch:300 loss:0.04096240922808647, acc:0.9885001182556152\n",
      "epoch:15, batch:100 loss:0.040685027837753296, acc:0.9887001514434814"
     ]
    }
   ],
   "source": [
    "#%%timeit -r 1 -n 1\n",
    "epoch = 15\n",
    "batch_size = 128\n",
    "total_batch= len(train_X) / batch_size\n",
    "for ep in range(epoch+1):\n",
    "    for i in range(int(total_batch)+1):\n",
    "        rnd_idx = np.random.choice(train_X.shape[0], batch_size, replace=False)\n",
    "        batch_x = train_X[rnd_idx]\n",
    "        batch_y = train_Y[rnd_idx]\n",
    "        _, loss_s, acc_s, summary= sess.run([optimizer, loss_scar, acc_scar, merged_summary_op], feed_dict={X: batch_x, Y_:batch_y, keep_prob:0.5})\n",
    "        summary_writer_train.add_summary(summary, ep * total_batch + i)\n",
    "        if i%100 ==0:\n",
    "            loss_v, acc_v, loss_s, acc_s, summary= sess.run([loss, accuracy, loss_scar, acc_scar, merged_summary_op], feed_dict={X: validation_X , Y_: validation_Y, keep_prob:1.0 })\n",
    "            #acc = accuracy.eval({X: validation_X , Y_: validation_Y, keep_prob:1.0})\n",
    "            #los=loss.eval({X: validation_X , Y_: validation_Y, keep_prob:1.0})\n",
    "            summary_writer_validation.add_summary(summary, ep * total_batch + i)\n",
    "            updateProgress('epoch:{x0}, batch:{x4} loss:{x3}, acc:{x2}'.format(x0=ep,x1=i,x2=acc_v,x3=loss_v,x4=i))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 抓出前五筆訓練資料的預測結果 Y_softmax (注意：這個是one-hot的格式)\n",
    "pred_tmp = pred.eval(feed_dict={X: train_X[21:30], keep_prob:1.0})\n",
    "pred_tmp_df = pd.DataFrame(pred_tmp)\n",
    "pred_tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = pred_tmp_df.apply(np.argmax,axis=1)\n",
    "print('predict: ',_.values)\n",
    "showX(train_X[21:30])\n",
    "print('answer: ',train_y[21:30])\n",
    "\n",
    "print('第21~30筆資料的比對結果:',pd.DataFrame(_))\n",
    "\n",
    "_ = correct_pred.eval({X: train_X[21:30] , Y_: train_Y[21:30], keep_prob:1.0})\n",
    "print('第21~30筆資料的比對結果:',pd.DataFrame(_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='算一下正'></a>\n",
    "### F. 算一下正確率Accuracy (用Testing Data)\n",
    "- unseen data\n",
    "- generalize from the training set to the test set\n",
    "- 泛化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict all X and get the accuracy\n",
    "_ = accuracy.eval({X: test_X , Y_: test_Y, keep_prob:1.0})\n",
    "print('Accuracy:',_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sess.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
